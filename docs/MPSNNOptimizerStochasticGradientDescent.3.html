<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>

<style>
@media (prefers-color-scheme: dark) {
  body {
    background: #000;
    color: #d0d0d0;
  }

  a, a:visited {
    color: #1899eb;
  }
}
</style>

  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    .Nd, .Bf, .Op { display: inline; }
    .Pa, .Ad { font-style: italic; }
    .Ms { font-weight: bold; }
    .Bl-diag > dt { font-weight: bold; }
    code.Nm, .Fl, .Cm, .Ic, code.In, .Fd, .Fn, .Cd { font-weight: bold;
      font-family: inherit; }
  </style>
  <title>MPSNNOptimizerStochasticGradientDescent(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSNNOptimizerStochasticGradientDescent(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSNNOptimizerStochasticGradientDescent(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
<p class="Pp">MPSNNOptimizerStochasticGradientDescent</p>
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSNNOptimizers.h&gt;</p>
<p class="Pp">Inherits <b>MPSNNOptimizer</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
<p class="Pp">(nonnull instancetype) - <b>initWithDevice:</b>
  <br/>
  (nonnull instancetype) - <b>initWithDevice:learningRate:</b>
  <br/>
  (nonnull instancetype) -
    <b>initWithDevice:momentumScale:useNestrovMomentum:optimizerDescriptor:</b>
  <br/>
  (void) -
    <b>encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:resultValuesVector:</b>
  <br/>
  (void) -
    <b>encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:resultState:</b>
  <br/>
  (void) -
    <b>encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:resultState:</b>
  <br/>
  (void) -
    <b>encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:resultState:</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
<p class="Pp">float <b>momentumScale</b>
  <br/>
  BOOL <b>useNestrovMomentum</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Additional_Inherited_Members"><a class="permalink" href="#Additional_Inherited_Members">Additional
  Inherited Members</a></h2>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
<p class="Pp">The <b>MPSNNOptimizerStochasticGradientDescent</b> performs a
    gradient descent with an optional momentum Update RMSProp is also known as
    root mean square propagation.</p>
<p class="Pp">useNestrov == NO: m[t] = momentumScale * m[t-1] + learningRate * g
    variable = variable - m[t]</p>
<p class="Pp">useNestrov == YES: m[t] = momentumScale * m[t-1] + g variable =
    variable - (learningRate * (g + m[t] * momentumScale))</p>
<p class="Pp"></p>
<pre>
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- (void) encodeToCommandBuffer: (__nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSCNNBatchNormalizationState</b>
  *__nonnull)
  batchNormalizationGradientState(<b>MPSCNNBatchNormalizationState</b>
  *__nonnull) batchNormalizationSourceState(nullable NSArray&lt;
  <b>MPSVector</b> * &gt; *) inputMomentumVectors(nonnull
  <b>MPSCNNNormalizationGammaAndBetaState</b> *) resultState</h2>
<p class="Pp">Encode an <b>MPSNNOptimizerStochasticGradientDescent</b> object to
    a command buffer to perform out of place update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>batchNormalizationGradientState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with gradients for this update.
<br/>
<i>batchNormalizationSourceState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with original gamma/beta for this update.
<br/>
<i>inputMomentumVectors</i> An array <b>MPSVector</b> object which specifies the
  gradient momentum vectors which will be updated and overwritten. The index 0
  corresponds to gamma, index 1 corresponds to beta, array can be of size 1 in
  which case beta won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNNormalizationGammaAndBetaState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
<br/>
        useNestrov == NO:
<br/>
            m[t]     = momentumScale * m[t-1] + learningRate * g
<br/>
            variable = variable - m[t]
<br/>
        useNestrov == YES:
<br/>
            m[t]     = momentumScale * m[t-1] + g
<br/>
            variable = variable - (learningRate * (g + m[t] * momentumScale))
<br/>
        inputMomentumVector == nil
<br/>
            variable = variable - (learningRate * g)
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeToCommandBuffer: (__nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSCNNBatchNormalizationState</b>
  *__nonnull) batchNormalizationState(nullable NSArray&lt; <b>MPSVector</b> *
  &gt; *) inputMomentumVectors(nonnull
  <b>MPSCNNNormalizationGammaAndBetaState</b> *) resultState</h2>
<p class="Pp">Encode an <b>MPSNNOptimizerStochasticGradientDescent</b> object to
    a command buffer to perform out of place update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>batchNormalizationState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with gradients and original gamma/beta for this update.
<br/>
<i>inputMomentumVectors</i> An array <b>MPSVector</b> object which specifies the
  gradient momentum vectors which will be updated and overwritten. The index 0
  corresponds to gamma, index 1 corresponds to beta, array can be of size 1 in
  which case beta won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNNormalizationGammaAndBetaState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
<br/>
        useNestrov == NO:
<br/>
            m[t]     = momentumScale * m[t-1] + learningRate * g
<br/>
            variable = variable - m[t]
<br/>
        useNestrov == YES:
<br/>
            m[t]     = momentumScale * m[t-1] + g
<br/>
            variable = variable - (learningRate * (g + m[t] * momentumScale))
<br/>
        inputMomentumVector == nil
<br/>
            variable = variable - (learningRate * g)
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeToCommandBuffer: (__nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSCNNConvolutionGradientState</b>
  *__nonnull)
  convolutionGradientState(<b>MPSCNNConvolutionWeightsAndBiasesState</b>
  *__nonnull) convolutionSourceState(nullable NSArray&lt; <b>MPSVector</b> *
  &gt; *) inputMomentumVectors(nonnull
  <b>MPSCNNConvolutionWeightsAndBiasesState</b> *) resultState</h2>
<p class="Pp">Encode an <b>MPSNNOptimizerStochasticGradientDescent</b> object to
    a command buffer to perform out of place update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>convolutionGradientState</i> <b>A</b> valid
  <b>MPSCNNConvolutionGradientState</b> object which specifies the input state
  with gradients for this update.
<br/>
<i>convolutionSourceState</i> <b>A</b> valid
  <b>MPSCNNConvolutionWeightsAndBiasesState</b> object which specifies the input
  state with values to be updated.
<br/>
<i>inputMomentumVectors</i> An array <b>MPSVector</b> object which specifies the
  gradient momentum vectors which will be updated and overwritten. The index 0
  corresponds to weights, index 1 corresponds to biases, array can be of size 1
  in which case biases won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNConvolutionWeightsAndBiasesState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
<br/>
        useNestrov == NO:
<br/>
            m[t]     = momentumScale * m[t-1] + learningRate * g
<br/>
            variable = variable - m[t]
<br/>
        useNestrov == YES:
<br/>
            m[t]     = momentumScale * m[t-1] + g
<br/>
            variable = variable - (learningRate * (g + m[t] * momentumScale))
<br/>
        inputMomentumVector == nil
<br/>
            variable = variable - (learningRate * g)
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeToCommandBuffer: (nonnull id&lt; MTLCommandBuffer
  &gt;) commandBuffer(nonnull <b>MPSVector</b> *) inputGradientVector(nonnull
  <b>MPSVector</b> *) inputValuesVector(nullable <b>MPSVector</b> *)
  inputMomentumVector(nonnull <b>MPSVector</b> *) resultValuesVector</h2>
<p class="Pp">Encode an <b>MPSNNOptimizerStochasticGradientDescent</b> object to
    a command buffer to perform out of place update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>inputGradientVector</i> <b>A</b> valid <b>MPSVector</b> object which
  specifies the input vector of gradients for this update.
<br/>
<i>inputValuesVector</i> <b>A</b> valid <b>MPSVector</b> object which specifies
  the input vector of values to be updated.
<br/>
<i>inputMomentumVector</i> <b>A</b> valid <b>MPSVector</b> object which
  specifies the gradient momentum vector which will be updated and overwritten.
<br/>
<i>resultValuesVector</i> <b>A</b> valid <b>MPSVector</b> object which specifies
  the resultValues vector which will be updated and overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
<br/>
        useNestrov == NO:
<br/>
            m[t]     = momentumScale * m[t-1] + learningRate * g
<br/>
            variable = variable - m[t]
<br/>
        useNestrov == YES:
<br/>
            m[t]     = momentumScale * m[t-1] + g
<br/>
            variable = variable - (learningRate * (g + m[t] * momentumScale))
<br/>
        inputMomentumVector == nil
<br/>
            variable = variable - (learningRate * g)
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          m[t] is momentum of gradients it is a state we keep updating every update iteration.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) initWithDevice: (nonnull id&lt;
  MTLDevice &gt;) device</h2>
<p class="Pp">Standard init with default properties per filter type</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device that the filter will be used on.
  May not be NULL.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">a pointer to the newly initialized object. This will
  fail, returning nil if the device is not supported. Devices must be
  MTLFeatureSet_iOS_GPUFamily2_v1 or later.</div>
<p class="Pp">Reimplemented from <b>MPSNNOptimizer</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt;
  MTLDevice &gt;) device(float) learningRate</h2>
<p class="Pp">Convenience initialization for the momentum update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device on which the kernel will
  execute.
<br/>
<i>learningRate</i> The learningRate which will be applied</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid
  <b>MPSNNOptimizerStochasticGradientDescent</b> object or nil, if
  failure.</div>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt;
  MTLDevice &gt;) device(float) momentumScale(BOOL) useNestrovMomentum(nonnull
  <b>MPSNNOptimizerDescriptor</b> *) optimizerDescriptor</h2>
<p class="Pp">Full initialization for the momentum update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device on which the kernel will
  execute.
<br/>
<i>momentumScale</i> The momentumScale to update momentum for values array
<br/>
<i>useNestrovMomentum</i> Use the Nestrov style momentum update
<br/>
<i>optimizerDescriptor</i> The optimizerDescriptor which will have a bunch of
  properties to be applied</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid MPSNNOptimizerMomentum object or nil, if
  failure.</div>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- momentumScale [read]<b>, [nonatomic]</b>, [assign]<b></b></h2>
<p class="Pp">The momentumScale at which we update momentum for values array
    Default value is 0.0</p>
</section>
<section class="Ss">
<h2 class="Ss">- useNestrovMomentum [read]<b>, [nonatomic]</b>,
  [assign]<b></b></h2>
<p class="Pp">Nestrov momentum is considered an improvement on the usual
    momentum update Default value is NO</p>
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
<p class="Pp">Generated automatically by Doxygen for
    MetalPerformanceShaders.framework from the source code.</p>
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
