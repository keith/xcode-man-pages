<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>

<style>
@media (prefers-color-scheme: dark) {
  body {
    background: #000;
    color: #d0d0d0;
  }

  a, a:visited {
    color: #1899eb;
  }
}
</style>

  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    .Nd, .Bf, .Op { display: inline; }
    .Pa, .Ad { font-style: italic; }
    .Ms { font-weight: bold; }
    .Bl-diag > dt { font-weight: bold; }
    code.Nm, .Fl, .Cm, .Ic, code.In, .Fd, .Fn, .Cd { font-weight: bold;
      font-family: inherit; }
  </style>
  <title>MPSGRUDescriptor(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSGRUDescriptor(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSGRUDescriptor(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
<p class="Pp">MPSGRUDescriptor</p>
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSRNNLayer.h&gt;</p>
<p class="Pp">Inherits <b>MPSRNNDescriptor</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Class_Methods"><a class="permalink" href="#Class_Methods">Class
  Methods</a></h2>
<br/>
<p class="Pp">(nonnull instancetype) +
    <b>createGRUDescriptorWithInputFeatureChannels:outputFeatureChannels:</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
<p class="Pp">id&lt; <b>MPSCNNConvolutionDataSource</b> &gt;
    <b>inputGateInputWeights</b>
  <br/>
  id&lt; <b>MPSCNNConvolutionDataSource</b> &gt;
    <b>inputGateRecurrentWeights</b>
  <br/>
  id&lt; <b>MPSCNNConvolutionDataSource</b> &gt;
    <b>recurrentGateInputWeights</b>
  <br/>
  id&lt; <b>MPSCNNConvolutionDataSource</b> &gt;
    <b>recurrentGateRecurrentWeights</b>
  <br/>
  id&lt; <b>MPSCNNConvolutionDataSource</b> &gt; <b>outputGateInputWeights</b>
  <br/>
  id&lt; <b>MPSCNNConvolutionDataSource</b> &gt;
    <b>outputGateRecurrentWeights</b>
  <br/>
  id&lt; <b>MPSCNNConvolutionDataSource</b> &gt;
    <b>outputGateInputGateWeights</b>
  <br/>
  float <b>gatePnormValue</b>
  <br/>
  BOOL <b>flipOutputGates</b>
  <br/>
  <br/>
</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
<p class="Pp">This depends on Metal.framework The <b>MPSGRUDescriptor</b>
    specifies a GRU (Gated Recurrent Unit) block/layer descriptor. The RNN layer
    initialized with a <b>MPSGRUDescriptor</b> transforms the input data (image
    or matrix), and previous output with a set of filters, each producing one
    feature map in the output data according to the Gated unit formulae detailed
    below. The user may provide the GRU unit a single input or a sequence of
    inputs. The layer also supports p-norm gating (Detailed in:
    https://arxiv.org/abs/1608.03639 ).</p>
<p class="Pp"></p>
<pre>Description of operation:
</pre>
<p class="Pp">Let x_j be the input data (at time index t of sequence, j index
    containing quadruplet: batch index, x,y and feature index (x=y=0 for
    matrices)). Let h0_j be the recurrent input (previous output) data from
    previous time step (at time index t-1 of sequence). Let h_i be the proposed
    new output. Let h1_i be the output data produced at this time step.</p>
<p class="Pp">Let Wz_ij, Uz_ij, be the input gate weights for input and
    recurrent input data respectively Let bi_i be the bias for the input
  gate</p>
<p class="Pp">Let Wr_ij, Ur_ij be the recurrent gate weights for input and
    recurrent input data respectively Let br_i be the bias for the recurrent
    gate</p>
<p class="Pp">Let Wh_ij, Uh_ij, Vh_ij, be the output gate weights for input,
    recurrent gate and input gate respectively Let bh_i be the bias for the
    output gate</p>
<p class="Pp">Let gz(x), gr(x), gh(x) be the neuron activation function for the
    input, recurrent and output gates Let p &gt; 0 be a scalar variable
    (typicall p &gt;= 1.0) that defines the p-norm gating norm value.</p>
<p class="Pp">Then the output of the Gated Recurrent Unit layer is computed as
    follows:</p>
<p class="Pp"></p>
<pre>
<br/>
    z_i = gz(  Wz_ij * x_j  +  Uz_ij * h0_j  +  bz_i  )
<br/>
    r_i = gr(  Wr_ij * x_j  +  Ur_ij * h0_j  +  br_i  )
<br/>
    c_i =      Uh_ij * (r_j h0_j)  +  Vh_ij * (z_j h0_j)
<br/>
    h_i = gh(  Wh_ij * x_j  + c_i + bh_i  )
h1_i = ( 1 - z_i ^ p)^(1/p) h_i + z_i h0_i
</pre>
<p class="Pp">The '*' stands for convolution (see
    <b>MPSRNNImageInferenceLayer</b>) or matrix-vector/matrix multiplication
    (see <b>MPSRNNMatrixInferenceLayer</b>). Summation is over index j (except
    for the batch index), but there is no summation over repeated index i - the
    output index. Note that for validity all intermediate images have to be of
    same size and all U and V matrices have to be square (ie.
    outputFeatureChannels == inputFeatureChannels in those). Also the bias terms
    are scalars wrt. spatial dimensions. The conventional GRU block is achieved
    by setting Vh = 0 (nil) and the so-called Minimal Gated Unit is achieved
    with Uh = 0. (The Minimal Gated Unit is detailed in:
    https://arxiv.org/abs/1603.09420 and there they call z_i the value of the
    forget gate).</p>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="+_(nonnull_instancetype)_createGRUDescriptorWithInputFeatureChannels:_(NSUInteger)_inputFeatureChannels(NSUInteger)_outputFeatureChannels"><a class="permalink" href="#+_(nonnull_instancetype)_createGRUDescriptorWithInputFeatureChannels:_(NSUInteger)_inputFeatureChannels(NSUInteger)_outputFeatureChannels">+
  (nonnull instancetype) createGRUDescriptorWithInputFeatureChannels:
  (NSUInteger) inputFeatureChannels(NSUInteger) outputFeatureChannels</a></h2>
<p class="Pp">Creates a GRU descriptor.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>inputFeatureChannels</i> The number of feature
  channels in the input image/matrix. Must be &gt;= 1.
<br/>
<i>outputFeatureChannels</i> The number of feature channels in the output
  image/matrix. Must be &gt;= 1.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSGRUDescriptor</b> object or nil, if
  failure.</div>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- flipOutputGates [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></h2>
<p class="Pp">If YES then the GRU-block output formula is changed to: h1_i = ( 1
    - z_i ^ p)^(1/p) h0_i + z_i h_i. Defaults to NO.</p>
</section>
<section class="Ss">
<h2 class="Ss">- gatePnormValue [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></h2>
<p class="Pp">The p-norm gating norm value as specified by the GRU formulae.
    Defaults to 1.0f.</p>
</section>
<section class="Ss">
<h2 class="Ss">- inputGateInputWeights [read]<b>, [write]</b>, [nonatomic]<b>,
  [retain]</b></h2>
<p class="Pp">Contains weights 'Wz_ij', bias 'bz_i' and neuron 'gz' from the GRU
    formula. If nil then assumed zero weights, bias and no neuron (identity
    mapping). Defaults to nil.</p>
</section>
<section class="Ss">
<h2 class="Ss">- inputGateRecurrentWeights [read]<b>, [write]</b>,
  [nonatomic]<b>, [retain]</b></h2>
<p class="Pp">Contains weights 'Uz_ij' from the GRU formula. If nil then assumed
    zero weights. Defaults to nil.</p>
</section>
<section class="Ss">
<h2 class="Ss">- outputGateInputGateWeights [read]<b>, [write]</b>,
  [nonatomic]<b>, [retain]</b></h2>
<p class="Pp">Contains weights 'Vh_ij' - can be used to implement the 'Minimally
    Gated Unit'. If nil then assumed zero weights. Defaults to nil.</p>
</section>
<section class="Ss">
<h2 class="Ss">- outputGateInputWeights [read]<b>, [write]</b>, [nonatomic]<b>,
  [retain]</b></h2>
<p class="Pp">Contains weights 'Wh_ij', bias 'bh_i' and neuron 'gh' from the GRU
    formula. If nil then assumed zero weights, bias and no neuron (identity
    mapping).Defaults to nil.</p>
</section>
<section class="Ss">
<h2 class="Ss">- outputGateRecurrentWeights [read]<b>, [write]</b>,
  [nonatomic]<b>, [retain]</b></h2>
<p class="Pp">Contains weights 'Uh_ij' from the GRU formula. If nil then assumed
    zero weights. Defaults to nil.</p>
</section>
<section class="Ss">
<h2 class="Ss">- recurrentGateInputWeights [read]<b>, [write]</b>,
  [nonatomic]<b>, [retain]</b></h2>
<p class="Pp">Contains weights 'Wr_ij', bias 'br_i' and neuron 'gr' from the GRU
    formula. If nil then assumed zero weights, bias and no neuron (identity
    mapping).Defaults to nil.</p>
</section>
<section class="Ss">
<h2 class="Ss">- recurrentGateRecurrentWeights [read]<b>, [write]</b>,
  [nonatomic]<b>, [retain]</b></h2>
<p class="Pp">Contains weights 'Ur_ij' from the GRU formula. If nil then assumed
    zero weights.Defaults to nil.</p>
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
<p class="Pp">Generated automatically by Doxygen for
    MetalPerformanceShaders.framework from the source code.</p>
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
