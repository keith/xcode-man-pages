<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   Generated from file '/Library/Caches/com.apple.xbs/Sources/tcl/tcl-129/tcl_ext/tcllib/tcllib/modules/amazon-s3/S3.man' by tcllib/doctools with format 'nroff'
   Copyright (c) Copyright 2006,2008 Darren New. All Rights Reserved. See LICENSE.TXT for terms.
  
   The definitions below are for supplemental macros used in Tcl/Tk
   manual entries.
  
   .AP type name in/out ?indent?
  	Start paragraph describing an argument to a library procedure.
  	type is type of argument (int, etc.), in/out is either "in", "out",
  	or "in/out" to describe whether procedure reads or modifies arg,
  	and indent is equivalent to second arg of .IP (shouldn't ever be
  	needed;  use .AS below instead)
  
   .AS ?type? ?name?
  	Give maximum sizes of arguments for setting tab stops.  Type and
  	name are examples of largest possible arguments that will be passed
  	to .AP later.  If args are omitted, default tab stops are used.
  
   .BS
  	Start box enclosure.  From here until next .BE, everything will be
  	enclosed in one large box.
  
   .BE
  	End of box enclosure.
  
   .CS
  	Begin code excerpt.
  
   .CE
  	End code excerpt.
  
   .VS ?version? ?br?
  	Begin vertical sidebar, for use in marking newly-changed parts
  	of man pages.  The first argument is ignored and used for recording
  	the version when the .VS was added, so that the sidebars can be
  	found and removed when they reach a certain age.  If another argument
  	is present, then a line break is forced before starting the sidebar.
  
   .VE
  	End of vertical sidebar.
  
   .DS
  	Begin an indented unfilled display.
  
   .DE
  	End of indented unfilled display.
  
   .SO
  	Start of list of standard options for a Tk widget.  The
  	options follow on successive lines, in four columns separated
  	by tabs.
  
   .SE
  	End of list of standard options for a Tk widget.
  
   .OP cmdName dbName dbClass
  	Start of description of a specific option.  cmdName gives the
  	option's name as specified in the class command, dbName gives
  	the option's name in the option database, and dbClass gives
  	the option's class in the option database.
  
   .UL arg1 arg2
  	Print arg1 underlined, then print arg2 normally.
  
   RCS: @(#) $Id: man.macros,v 1.1 2009/01/30 04:56:47 andreas_kupries Exp $
  
  	# Set up traps and other miscellaneous stuff for Tcl/Tk man pages.
  	# Start an argument description
  .b
  	# define tabbing values for .AP
  
  	# BS - start boxed text
  	# ^y = starting y location
  	# ^b = 1
  	# BE - end boxed text (draw box now)
  	Draw four-sided box normally, but don't draw top of
  	box if the box started on an earlier page.
  	# VS - start vertical sidebar
  	# ^Y = starting y location
  	# ^v = 1 (for troff;  for nroff this doesn't matter)
  	# VE - end of vertical sidebar
  	# Special macro to handle page bottom:  finish off current
  	# box/sidebar if in box/sidebar mode, then invoked standard
  	# page bottom macro.
  	Draw three-sided box if this is the box's first page,
  	draw two sides but no top otherwise.
  	# DS - begin display
  	# DE - end display
  	# SO - start of list of standard options
  	# SE - end of list of standard options
  	# OP - start of full description for a single option
  	# CS - begin code excerpt
  	# CE - end code excerpt
 -->
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
    div.Nd, div.Bf, div.Op { display: inline; }
    span.Pa, span.Ad { font-style: italic; }
    span.Ms { font-weight: bold; }
    dl.Bl-diag > dt { font-weight: bold; }
    code.Nm, code.Fl, code.Cm, code.Ic, code.In, code.Fd, code.Fn,
    code.Cd { font-weight: bold; font-family: inherit; }
  </style>
  <title>S3(n)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">S3(n)</td>
    <td class="head-vol">Amazon S3 Web Service Interface</td>
    <td class="head-rtitle">S3(n)</td>
  </tr>
</table>
<div class="manual-text">
<br/>
<pre>

</pre>
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
S3 - Amazon S3 Web Service Interface
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
package require <b>Tcl 8.5</b>
<p class="Pp">package require <b>sha1 1.0</b></p>
<p class="Pp">package require <b>md5 2.0</b></p>
<p class="Pp">package require <b>base64 2.3</b></p>
<p class="Pp">package require <b>xsxp 1.0</b></p>
<p class="Pp"><b>S3::Configure</b> ?<b>-reset</b> <i>boolean</i>?
    ?<b>-retries</b> <i>integer</i>? ?<b>-accesskeyid</b> <i>idstring</i>?
    ?<b>-secretaccesskey</b> <i>idstring</i>? ?<b>-service-access-point</b>
    <i>FQDN</i>? ?<b>-use-tls</b> <i>boolean</i>? ?<b>-default-compare</b>
    <i>always|never|exists|missing|newer|date|checksum|different</i>?
    ?<b>-default-separator</b> <i>string</i>? ?<b>-default-acl</b>
    <i>private|public-read|public-read-write|authenticated-read|keep|calc</i>?
    ?<b>-default-bucket</b> <i>bucketname</i>?</p>
<p class="Pp"><b>S3::SuggestBucket</b> ?<i>name</i>?</p>
<p class="Pp"><b>S3::REST</b> <i>dict</i></p>
<p class="Pp"><b>S3::ListAllMyBuckets</b> ?<b>-blocking</b> <i>boolean</i>?
    ?<b>-parse-xml</b> <i>xmlstring</i>? ?<b>-result-type</b>
    <i>REST|xml|pxml|dict|names|owner</i>?</p>
<p class="Pp"><b>S3::PutBucket</b> ?<b>-bucket</b> <i>bucketname</i>?
    ?<b>-blocking</b> <i>boolean</i>? ?<b>-acl</b>
    <i>{}|private|public-read|public-read-write|authenticated-read</i>?</p>
<p class="Pp"><b>S3::DeleteBucket</b> ?<b>-bucket</b> <i>bucketname</i>?
    ?<b>-blocking</b> <i>boolean</i>?</p>
<p class="Pp"><b>S3::GetBucket</b> ?<b>-bucket</b> <i>bucketname</i>?
    ?<b>-blocking</b> <i>boolean</i>? ?<b>-parse-xml</b> <i>xmlstring</i>?
    ?<b>-max-count</b> <i>integer</i>? ?<b>-prefix</b> <i>prefixstring</i>?
    ?<b>-delimiter</b> <i>delimiterstring</i>? ?<b>-result-type</b>
    <i>REST|xml|pxml|names|dict</i>?</p>
<p class="Pp"><b>S3::Put</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-resource</b>
    <i>resourcename</i> ?<b>-blocking</b> <i>boolean</i>? ?<b>-file</b>
    <i>filename</i>? ?<b>-content</b> <i>contentstring</i>? ?<b>-acl</b>
    <i>private|public-read|public-read-write|authenticated-read|calc|keep</i>?
    ?<b>-content-type</b> <i>contenttypestring</i>? ?<b>-x-amz-meta-*</b>
    <i>metadatatext</i>? ?<b>-compare</b> <i>comparemode</i>?</p>
<p class="Pp"><b>S3::Get</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-resource</b>
    <i>resourcename</i> ?<b>-blocking</b> <i>boolean</i>? ?<b>-compare</b>
    <i>comparemode</i>? ?<b>-file</b> <i>filename</i>? ?<b>-content</b>
    <i>contentvarname</i>? ?<b>-timestamp</b> <i>aws|now</i>? ?<b>-headers</b>
    <i>headervarname</i>?</p>
<p class="Pp"><b>S3::Head</b> ?<b>-bucket</b> <i>bucketname</i>?
    <b>-resource</b> <i>resourcename</i> ?<b>-blocking</b> <i>boolean</i>?
    ?<b>-dict</b> <i>dictvarname</i>? ?<b>-headers</b> <i>headersvarname</i>?
    ?<b>-status</b> <i>statusvarname</i>?</p>
<p class="Pp"><b>S3::GetAcl</b> ?<b>-blocking</b> <i>boolean</i>?
    ?<b>-bucket</b> <i>bucketname</i>? <b>-resource</b> <i>resourcename</i>
    ?<b>-result-type</b> <i>REST|xml|pxml</i>?</p>
<p class="Pp"><b>S3::PutAcl</b> ?<b>-blocking</b> <i>boolean</i>?
    ?<b>-bucket</b> <i>bucketname</i>? <b>-resource</b> <i>resourcename</i>
    ?<b>-acl</b> <i>new-acl</i>?</p>
<p class="Pp"><b>S3::Delete</b> ?<b>-bucket</b> <i>bucketname</i>?
    <b>-resource</b> <i>resourcename</i> ?<b>-blocking</b> <i>boolean</i>?
    ?<b>-status</b> <i>statusvar</i>?</p>
<p class="Pp"><b>S3::Push</b> ?<b>-bucket</b> <i>bucketname</i>?
    <b>-directory</b> <i>directoryname</i> ?<b>-prefix</b> <i>prefixstring</i>?
    ?<b>-compare</b> <i>comparemode</i>? ?<b>-x-amz-meta-*</b>
    <i>metastring</i>? ?<b>-acl</b> <i>aclcode</i>? ?<b>-delete</b>
    <i>boolean</i>? ?<b>-error</b> <i>throw|break|continue</i>?
    ?<b>-progress</b> <i>scriptprefix</i>?</p>
<p class="Pp"><b>S3::Pull</b> ?<b>-bucket</b> <i>bucketname</i>?
    <b>-directory</b> <i>directoryname</i> ?<b>-prefix</b> <i>prefixstring</i>?
    ?<b>-blocking</b> <i>boolean</i>? ?<b>-compare</b> <i>comparemode</i>?
    ?<b>-delete</b> <i>boolean</i>? ?<b>-timestamp</b> <i>aws|now</i>?
    ?<b>-error</b> <i>throw|break|continue</i>? ?<b>-progress</b>
    <i>scriptprefix</i>?</p>
<p class="Pp"><b>S3::Toss</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-prefix</b>
    <i>prefixstring</i> ?<b>-blocking</b> <i>boolean</i>? ?<b>-error</b>
    <i>throw|break|continue</i>? ?<b>-progress</b> <i>scriptprefix</i>?</p>
<p class="Pp"></p>
<pre>

</pre>
</section>
<section class="Sh">
<h1 class="Sh" id="DESCRIPTION"><a class="permalink" href="#DESCRIPTION">DESCRIPTION</a></h1>
This package provides access to Amazon's Simple Storage Solution web service.
<p class="Pp">As a quick summary, Amazon Simple Storage Solution provides a
    for-fee web service allowing the storage of arbitrary data as
    &quot;resources&quot; within &quot;buckets&quot; online. See
    <i>http://www.amazonaws.com/</i> for details on that system. Access to the
    service is via HTTP (SOAP or REST). Much of this documentation will not make
    sense if you're not familiar with the terms and functionality of the Amazon
    S3 service.</p>
<p class="Pp">This package provides services for reading and writing the data
    items via the REST interface. It also provides some higher-level operations.
    Other packages in the same distribution provide for even more
  functionality.</p>
<p class="Pp">Copyright 2006 Darren New. All Rights Reserved. NO WARRANTIES OF
    ANY TYPE ARE PROVIDED. COPYING OR USE INDEMNIFIES THE AUTHOR IN ALL WAYS.
    This software is licensed under essentially the same terms as Tcl. See
    LICENSE.txt for the terms.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="ERROR_REPORTING"><a class="permalink" href="#ERROR_REPORTING">ERROR
  REPORTING</a></h1>
The error reporting from this package makes use of $errorCode to provide more
  details on what happened than simply throwing an error. Any error caught by
  the S3 package (and we try to catch them all) will return with an $errorCode
  being a list having at least three elements. In all cases, the first element
  will be &quot;S3&quot;. The second element will take on one of six values,
  with that element defining the value of the third and subsequent elements.
  S3::REST does not throw an error, but rather returns a dictionary with the
  keys &quot;error&quot;, &quot;errorInfo&quot;, and &quot;errorCode&quot; set.
  This allows for reliable background use. The possible second elements are
  these:
<dl class="Bl-tag">
  <dt>usage</dt>
  <dd>The usage of the package is incorrect. For example, a command has been
      invoked which requires the library to be configured before the library has
      been configured, or an invalid combination of options has been specified.
      The third element of $errorCode supplies the name of the parameter that
      was wrong. The fourth usually provides the arguments that were actually
      supplied to the throwing proc, unless the usage error isn't confined to a
      single proc.</dd>
  <dt>local</dt>
  <dd>Something happened on the local system which threw an error. For example,
      a request to upload or download a file was made and the file permissions
      denied that sort of access. The third element of $errorCode is the
      original $errorCode.</dd>
  <dt>socket</dt>
  <dd>Something happened with the socket. It closed prematurely, or some other
      condition of failure-to-communicate-with-Amazon was detected. The third
      element of $errorCode is the original $errorCode, or sometimes the message
      from fcopy, or ...?</dd>
  <dt>remote</dt>
  <dd>The Amazon web service returned an error code outside the 2xx range in the
      HTTP header. In other words, everything went as documented, except this
      particular case was documented not to work. The third element is the
      dictionary returned from <b>::S3::REST</b>. Note that S3::REST itself
      never throws this error, but just returns the dictionary. Most of the
      higher-level commands throw for convenience, unless an argument indicates
      they should not. If something is documented as &quot;not throwing an S3
      remote error&quot;, it means a status return is set rather than throwing
      an error if Amazon returns a non-2XX HTTP result code.</dd>
  <dt>notyet</dt>
  <dd>The user obeyed the documentation, but the author has not yet gotten
      around to implementing this feature. (Right now, only TLS support and
      sophisticated permissions fall into this category, as well as the S3::Acl
      command.)</dd>
  <dt>xml</dt>
  <dd>The service has returned invalid XML, or XML whose schema is unexpected.
      For the high-level commands that accept service XML as input for parsing,
      this may also be thrown.</dd>
</dl>
</section>
<section class="Sh">
<h1 class="Sh" id="COMMANDS"><a class="permalink" href="#COMMANDS">COMMANDS</a></h1>
This package provides several separate levels of complexity.
<ul class="Bl-bullet">
  <li>The lowest level simply takes arguments to be sent to the service, sends
      them, retrieves the result, and provides it to the caller. <i>Note:</i>
      This layer allows both synchronous and event-driven processing. It depends
      on the MD5 and SHA1 and base64 packages from Tcllib (available at
      <i>http://tcllib.sourceforge.net/</i>). Note that <b>S3::Configure</b> is
      required for <b>S3::REST</b> to work due to the authentication portion, so
      we put that in the &quot;lowest level.&quot;</li>
  <li>The next layer parses the results of calls, allowing for functionality
      such as uploading only changed files, synchronizing directories, and so
      on. This layer depends on the <b>TclXML</b> package as well as the
      included <b>xsxp</b> package. These packages are package required when
      these more-sophisticated routines are called, so nothing breaks if they
      are not correctly installed.</li>
  <li>Also included is a separate program that uses the library. It provides
      code to parse $argv0 and $argv from the command line, allowing invocation
      as a tclkit, etc. (Not yet implmented.)</li>
  <li>Another separate program provides a GUI interface allowing drag-and-drop
      and other such functionality. (Not yet implemented.)</li>
  <li>Also built on this package is the OddJob program. It is a separate program
      designed to allow distribution of computational work units over Amazon's
      Elastic Compute Cloud web service.</li>
</ul>
<p class="Pp">The goal is to have at least the bottom-most layers implemented in
    pure Tcl using only that which comes from widely-available sources, such as
    Tcllib.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="LOW_LEVEL_COMMANDS"><a class="permalink" href="#LOW_LEVEL_COMMANDS">LOW
  LEVEL COMMANDS</a></h1>
These commands do not require any packages not listed above. They talk directly
  to the service, or they are utility or configuration routines. Note that the
  &quot;xsxp&quot; package was written to support this package, so it should be
  available wherever you got this package.
<dl class="Bl-tag">
  <dt><b>S3::Configure</b> ?<b>-reset</b> <i>boolean</i>? ?<b>-retries</b>
    <i>integer</i>? ?<b>-accesskeyid</b> <i>idstring</i>?
    ?<b>-secretaccesskey</b> <i>idstring</i>? ?<b>-service-access-point</b>
    <i>FQDN</i>? ?<b>-use-tls</b> <i>boolean</i>? ?<b>-default-compare</b>
    <i>always|never|exists|missing|newer|date|checksum|different</i>?
    ?<b>-default-separator</b> <i>string</i>? ?<b>-default-acl</b>
    <i>private|public-read|public-read-write|authenticated-read|keep|calc</i>?
    ?<b>-default-bucket</b> <i>bucketname</i>?</dt>
  <dd>There is one command for configuration, and that is <b>S3::Configure</b>.
      If called with no arguments, it returns a dictionary of key/value pairs
      listing all current settings. If called with one argument, it returns the
      value of that single argument. If called with two or more arguments, it
      must be called with pairs of arguments, and it applies the changes in
      order. There is only one set of configuration information per interpreter.
    <p class="Pp">The following options are accepted:</p>
  </dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-reset</b> <i>boolean</i></dt>
  <dd>By default, false. If true, any previous changes and any changes on the
      same call before the reset option will be returned to default values.</dd>
  <dt><b>-retries</b> <i>integer</i></dt>
  <dd>Default value is 3. If Amazon returns a 500 error, a retry after an
      exponential backoff delay will be tried this many times before finally
      throwing the 500 error. This applies to each call to <b>S3::REST</b> from
      the higher-level commands, but not to <b>S3::REST</b> itself. That is,
      <b>S3::REST</b> will always return httpstatus 500 if that's what it
      receives. Functions like <b>S3::Put</b> will retry the PUT call, and will
      also retry the GET and HEAD calls used to do content comparison. Changing
      this to 0 will prevent retries and their associated delays. In addition,
      socket errors (i.e., errors whose errorCode starts with &quot;S3
      socket&quot;) will be similarly retried after backoffs.</dd>
  <dt><b>-accesskeyid</b> <i>idstring</i></dt>
  <dd></dd>
  <dt><b>-secretaccesskey</b> <i>idstring</i></dt>
  <dd>Each defaults to an empty string. These must be set before any calls are
      made. This is your S3 ID. Once you sign up for an account, go to
      <i>http://www.amazonaws.com/</i>, sign in, go to the &quot;Your Web
      Services Account&quot; button, pick &quot;AWS Access Identifiers&quot;,
      and your access key ID and secret access keys will be available. All
      <b>S3::REST</b> calls are authenticated. Blame Amazon for the poor choice
      of names.</dd>
  <dt><b>-service-access-point</b> <i>FQDN</i></dt>
  <dd>Defaults to &quot;s3.amazonaws.com&quot;. This is the fully-qualified
      domain name of the server to contact for <b>S3::REST</b> calls. You should
      probably never need to touch this, unless someone else implements a
      compatible service, or you wish to test something by pointing the library
      at your own service.</dd>
  <dt><b>-slop-seconds</b> <i>integer</i></dt>
  <dd>When comparing dates between Amazon and the local machine, two dates
      within this many seconds of each other are considered the same. Useful for
      clock drift correction, processing overhead time, and so on.</dd>
  <dt><b>-use-tls</b> <i>boolean</i></dt>
  <dd>Defaults to false. This is not yet implemented. If true, <b>S3::REST</b>
      will negotiate a TLS connection to Amazon. If false, unencrypted
      connections are used.</dd>
  <dt><b>-bucket-prefix</b> <i>string</i></dt>
  <dd>Defaults to &quot;TclS3&quot;. This string is used by
      <b>S3::SuggestBucketName</b> if that command is passed an empty string as
      an argument. It is used to distinguish different applications using the
      Amazon service. Your application should always set this to keep from
      interfering with the buckets of other users of Amazon S3 or with other
      buckets of the same user.</dd>
  <dt><b>-default-compare</b>
    <i>always|never|exists|missing|newer|date|checksum|different</i></dt>
  <dd>Defaults to &quot;always.&quot; If no -compare is specified on
      <b>S3::Put</b>, <b>S3::Get</b>, or <b>S3::Delete</b>, this comparison is
      used. See those commands for a description of the meaning.</dd>
  <dt><b>-default-separator</b> <i>string</i></dt>
  <dd>Defaults to &quot;/&quot;. This is currently unused. It might make sense
      to use this for <b>S3::Push</b> and <b>S3::Pull</b>, but allowing
      resources to have slashes in their names that aren't marking directories
      would be problematic. Hence, this currently does nothing.</dd>
  <dt><b>-default-acl</b>
    <i>private|public-read|public-read-write|authenticated-read|keep|calc</i></dt>
  <dd>Defaults to an empty string. If no -acl argument is provided to
      <b>S3::Put</b> or <b>S3::Push</b>, this string is used (given as the
      x-amz-acl header if not keep or calc). If this is also empty, no x-amz-acl
      header is generated. This is <i>not</i> used by <b>S3::REST</b>.</dd>
  <dt><b>-default-bucket</b> <i>bucketname</i></dt>
  <dd>If no bucket is given to <b>S3::GetBucket</b>, <b>S3::PutBucket</b>,
      <b>S3::Get</b>, <b>S3::Put</b>, <b>S3::Head</b>, <b>S3::Acl</b>,
      <b>S3::Delete</b>, <b>S3::Push</b>, <b>S3::Pull</b>, or <b>S3::Toss</b>,
      and if this configuration variable is not an empty string (and not simply
      &quot;/&quot;), then this value will be used for the bucket. This is
      useful if one program does a large amount of resource manipulation within
      a single bucket.</dd>
</dl>
</div>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt><b>S3::SuggestBucket</b> ?<i>name</i>?</dt>
  <dd>The <b>S3::SuggestBucket</b> command accepts an optional string as a
      prefix and returns a valid bucket containing the <i>name</i> argument and
      the Access Key ID. This makes the name unique to the owner and to the
      application (assuming the application picks a good <i>name</i> argument).
      If no name is provided, the name from <b>S3::Configure</b>
      <i>-bucket-prefix</i> is used. If that too is empty (which is not the
      default), an error is thrown.</dd>
  <dt><b>S3::REST</b> <i>dict</i></dt>
  <dd>The <b>S3::REST</b> command takes as an argument a dictionary and returns
      a dictionary. The return dictionary has the same keys as the input
      dictionary, and includes additional keys as the result. The presence or
      absence of keys in the input dictionary can control the behavior of the
      routine. It never throws an error directly, but includes keys
      &quot;error&quot;, &quot;errorInfo&quot;, and &quot;errorCode&quot; if
      necessary. Some keys are required, some optional. The routine can run
      either in blocking or non-blocking mode, based on the presense of
      <b>resultvar</b> in the input dictionary. This requires the
      <i>-accesskeyid</i> and <i>-secretaccesskey</i> to be configured via
      <b>S3::Configure</b> before being called.
    <p class="Pp">The possible input keys are these:</p>
  </dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>verb</b> <i>GET|PUT|DELETE|HEAD</i></dt>
  <dd>This required item indicates the verb to be used.</dd>
  <dt><b>resource</b> <i>string</i></dt>
  <dd>This required item indicates the resource to be accessed. A leading / is
      added if not there already. It will be URL-encoded for you if necessary.
      Do not supply a resource name that is already URL-encoded.</dd>
  <dt>?<b>rtype</b> <i>torrent|acl</i>?</dt>
  <dd>This indicates a torrent or acl resource is being manipulated. Do not
      include this in the <b>resource</b> key, or the &quot;?&quot; separator
      will get URL-encoded.</dd>
  <dt>?<b>parameters</b> <i>dict</i>?</dt>
  <dd>This optional dictionary provides parameters added to the URL for the
      transaction. The keys must be in the correct case (which is confusing in
      the Amazon documentation) and the values must be valid. This can be an
      empty dictionary or omitted entirely if no parameters are desired. No
      other error checking on parameters is performed.</dd>
  <dt>?<b>headers</b> <i>dict</i>?</dt>
  <dd>This optional dictionary provides headers to be added to the HTTP request.
      The keys must be in <i>lower case</i> for the authentication to work. The
      values must not contain embedded newlines or carriage returns. This is
      primarily useful for adding x-amz-* headers. Since authentication is
      calculated by <b>S3::REST</b>, do not add that header here. Since
      content-type gets its own key, also do not add that header here.</dd>
  <dt>?<b>inbody</b> <i>contentstring</i>?</dt>
  <dd>This optional item, if provided, gives the content that will be sent. It
      is sent with a tranfer encoding of binary, and only the low bytes are
      used, so use [encoding convertto utf-8] if the string is a utf-8 string.
      This is written all in one blast, so if you are using non-blocking mode
      and the <b>inbody</b> is especially large, you may wind up blocking on the
      write socket.</dd>
  <dt>?<b>infile</b> <i>filename</i>?</dt>
  <dd>This optional item, if provided, and if <b>inbody</b> is not provided,
      names the file from which the body of the HTTP message will be
      constructed. The file is opened for reading and sent progressively by
      [fcopy], so it should not block in non-blocking mode even if the file is
      very large. The file is transfered in binary mode, so the bytes on your
      disk will match the bytes in your resource. Due to HTTP restrictions, it
      must be possible to use [file size] on this file to determine the size at
      the start of the transaction.</dd>
  <dt>?<b>S3chan</b> <i>channel</i>?</dt>
  <dd>This optional item, if provided, indicates the already-open socket over
      which the transaction should be conducted. If not provided, a connection
      is made to the service access point specified via <b>S3::Configure</b>,
      which is normally s3.amazonaws.com. If this is provided, the channel is
      not closed at the end of the transaction.</dd>
  <dt>?<b>outchan</b> <i>channel</i>?</dt>
  <dd>This optional item, if provided, indicates the already-open channel to
      which the body returned from S3 should be written. That is, to retrieve a
      large resource, open a file, set the translation mode, and pass the
      channel as the value of the key outchan. Output will be written to the
      channel in pieces so memory does not fill up unnecessarily. The channel is
      not closed at the end of the transaction.</dd>
  <dt>?<b>resultvar</b> <i>varname</i>?</dt>
  <dd>This optional item, if provided, indicates that <b>S3::REST</b> should run
      in non-blocking mode. The <i>varname</i> should be fully qualified with
      respect to namespaces and cannot be local to a proc. If provided, the
      result of the <b>S3::REST</b> call is assigned to this variable once
      everything has completed; use trace or vwait to know when this has
      happened. If this key is not provided, the result is simply returned from
      the call to <b>S3::REST</b> and no calls to the eventloop are invoked from
      within this call.</dd>
  <dt>?<b>throwsocket</b> <i>throw|return</i>?</dt>
  <dd>This optional item, if provided, indicates that <b>S3::REST</b> should
      throw an error if throwmode is throw and a socket error is encountered. It
      indicates that <b>S3::REST</b> should return the error code in the
      returned dictionary if a socket error is encountered and this is set to
      return. If <b>throwsocket</b> is set to <i>return</i> or if the call is
      not blocking, then a socket error (i.e., an error whose error code starts
      with &quot;S3 socket&quot; will be returned in the dictionary as
      <b>error</b>, <b>errorInfo</b>, and <b>errorCode</b>. If a foreground call
      is made (i.e., <b>resultvar</b> is not provided), and this option is not
      provided or is set to <i>throw</i>, then <b>error</b> will be invoked
      instead.</dd>
</dl>
</div>
<p class="Pp">Once the call to <b>S3::REST</b> completes, a new dict is
    returned, either in the <i>resultvar</i> or as the result of execution. This
    dict is a copy of the original dict with the results added as new keys. The
    possible new keys are these:</p>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>error</b> <i>errorstring</i></dt>
  <dd></dd>
  <dt><b>errorInfo</b> <i>errorstring</i></dt>
  <dd></dd>
  <dt><b>errorCode</b> <i>errorstring</i></dt>
  <dd>If an error is caught, these three keys will be set in the result. Note
      that <b>S3::REST</b> does <i>not</i> consider a non-2XX HTTP return code
      as an error. The <b>errorCode</b> value will be formatted according to the
      <b>ERROR REPORTING</b> description. If these are present, other keys
      described here might not be.</dd>
  <dt><b>httpstatus</b> <i>threedigits</i></dt>
  <dd>The three-digit code from the HTTP transaction. 2XX for good, 5XX for
      server error, etc.</dd>
  <dt><b>httpmessage</b> <i>text</i></dt>
  <dd>The textual result after the status code. &quot;OK&quot; or
      &quot;Forbidden&quot; or etc.</dd>
  <dt><b>outbody</b> <i>contentstring</i></dt>
  <dd>If <i>outchan</i> was not specified, this key will hold a reference to the
      (unencoded) contents of the body returned. If Amazon returned an error (a
      la the httpstatus not a 2XX value), the error message will be in
      <b>outbody</b> or written to <b>outchan</b> as appropriate.</dd>
  <dt><b>outheaders</b> <i>dict</i></dt>
  <dd>This contains a dictionary of headers returned by Amazon. The keys are
      always lower case. It's mainly useful for finding the x-amz-meta-*
      headers, if any, although things like last-modified and content-type are
      also useful. The keys of this dictionary are always lower case. Both keys
      and values are trimmed of extraneous whitespace.</dd>
</dl>
</div>
</section>
<section class="Sh">
<h1 class="Sh" id="HIGH_LEVEL_COMMANDS"><a class="permalink" href="#HIGH_LEVEL_COMMANDS">HIGH
  LEVEL COMMANDS</a></h1>
The routines in this section all make use of one or more calls to
  <b>S3::REST</b> to do their work, then parse and manage the data in a
  convenient way. All these commands throw errors as described in <b>ERROR
  REPORTING</b> unless otherwise noted.
<p class="Pp">In all these commands, all arguments are presented as name/value
    pairs, in any order. All the argument names start with a hyphen.</p>
<p class="Pp">There are a few options that are common to many of the commands,
    and those common options are documented here.</p>
<dl class="Bl-tag">
  <dt><b>-blocking</b> <i>boolean</i></dt>
  <dd>If provided and specified as false, then any calls to <b>S3:REST</b> will
      be non-blocking, and internally these routines will call [vwait] to get
      the results. In other words, these routines will return the same value,
      but they'll have event loops running while waiting for Amazon.</dd>
  <dt><b>-parse-xml</b> <i>xmlstring</i></dt>
  <dd>If provided, the routine skips actually communicating with Amazon, and
      instead behaves as if the XML string provided was returned as the body of
      the call. Since several of these routines allow the return of data in
      various formats, this argument can be used to parse existing XML to
      extract the bits of information that are needed. It's also helpful for
      testing.</dd>
  <dt><b>-bucket</b> <i>bucketname</i></dt>
  <dd>Almost every high-level command needs to know what bucket the resources
      are in. This option specifies that. (Only the command to list available
      buckets does not require this parameter.) This does not need to be
      URL-encoded, even if it contains special or non-ASCII characters. May or
      may not contain leading or trailing spaces - commands normalize the
      bucket. If this is not supplied, the value is taken from <b>S3::Configure
      -default-bucket</b> if that string isn't empty. Note that spaces and
      slashes are always trimmed from both ends and the rest must leave a valid
      bucket.</dd>
  <dt><b>-resource</b> <i>resourcename</i></dt>
  <dd>This specifies the resource of interest within the bucket. It may or may
      not start with a slash - both cases are handled. This does not need to be
      URL-encoded, even if it contains special or non-ASCII characters.</dd>
  <dt><b>-compare</b>
    <i>always|never|exists|missing|newer|date|checksum|different</i></dt>
  <dd>When commands copy resources to files or files to resources, the caller
      may specify that the copy should be skipped if the contents are the same.
      This argument specifies the conditions under which the files should be
      copied. If it is not passed, the result of <b>S3::Configure
      -default-compare</b> is used, which in turn defaults to
      &quot;always.&quot; The meanings of the various values are these:</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><i>always</i></dt>
  <dd>Always copy the data. This is the default.</dd>
  <dt><i>never</i></dt>
  <dd>Never copy the data. This is essentially a no-op, except in
      <b>S3::Push</b> and <b>S3::Pull</b> where the -delete flag might make a
      difference.</dd>
  <dt><i>exists</i></dt>
  <dd>Copy the data only if the destination already exists.</dd>
  <dt><i>missing</i></dt>
  <dd>Copy the data only if the destination does not already exist.</dd>
  <dt><i>newer</i></dt>
  <dd>Copy the data if the destination is missing, or if the date on the source
      is newer than the date on the destination by at least <b>S3::Configure
      -slop-seconds</b> seconds. If the source is Amazon, the date is taken from
      the Last-Modified header. If the source is local, it is taken as the mtime
      of the file. If the source data is specified in a string rather than a
      file, it is taken as right now, via [clock seconds].</dd>
  <dt><i>date</i></dt>
  <dd>Like <i>newer</i>, except copy if the date is newer <i>or</i> older.</dd>
  <dt><i>checksum</i></dt>
  <dd>Calculate the MD5 checksum on the local file or string, ask Amazon for the
      eTag of the resource, and copy the data if they're different. Copy the
      data also if the destination is missing. Note that this can be slow with
      large local files unless the C version of the MD5 support is
    available.</dd>
  <dt><i>different</i></dt>
  <dd>Copy the data if the destination does not exist. If the destination exists
      and an actual file name was specified (rather than a content string), and
      the date on the file differs from the date on the resource, copy the data.
      If the data is provided as a content string, the &quot;date&quot; is
      treated as &quot;right now&quot;, so it will likely always differ unless
      slop-seconds is large. If the dates are the same, the MD5 checksums are
      compared, and the data is copied if the checksums differ.</dd>
</dl>
</div>
<p class="Pp">Note that &quot;newer&quot; and &quot;date&quot; don't care about
    the contents, and &quot;checksum&quot; doesn't care about the dates, but
    &quot;different&quot; checks both.</p>
<dl class="Bl-tag">
  <dt><b>S3::ListAllMyBuckets</b> ?<b>-blocking</b> <i>boolean</i>?
    ?<b>-parse-xml</b> <i>xmlstring</i>? ?<b>-result-type</b>
    <i>REST|xml|pxml|dict|names|owner</i>?</dt>
  <dd>This routine performs a GET on the Amazon S3 service, which is defined to
      return a list of buckets owned by the account identified by the
      authorization header. (Blame Amazon for the dumb names.)</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-blocking</b> <i>boolean</i></dt>
  <dd>See above for standard definition.</dd>
  <dt><b>-parse-xml</b> <i>xmlstring</i></dt>
  <dd>See above for standard definition.</dd>
  <dt><b>-result-type</b> <i>REST</i></dt>
  <dd>The dictionary returned by <b>S3::REST</b> is the return value of
      <b>S3::ListAllMyBuckets</b>. In this case, a non-2XX httpstatus will not
      throw an error. You may not combine this with <i>-parse-xml</i>.</dd>
  <dt><b>-result-type</b> <i>xml</i></dt>
  <dd>The raw XML of the body is returned as the result (with no encoding
      applied).</dd>
  <dt><b>-result-type</b> <i>pxml</i></dt>
  <dd>The XML of the body as parsed by <b>xsxp::parse</b> is returned.</dd>
  <dt><b>-result-type</b> <i>dict</i></dt>
  <dd>A dictionary of interesting portions of the XML is returned. The
      dictionary contains the following keys:</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt>Owner/ID</dt>
  <dd>The Amazon AWS ID (in hex) of the owner of the bucket.</dd>
  <dt>Owner/DisplayName</dt>
  <dd>The Amazon AWS ID's Display Name.</dd>
  <dt>Bucket/Name</dt>
  <dd>A list of names, one for each bucket.</dd>
  <dt>Bucket/CreationDate</dt>
  <dd>A list of dates, one for each bucket, in the same order as Bucket/Name, in
      ISO format (as returned by Amazon).</dd>
</dl>
</div>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt><b>-result-type</b> <i>names</i></dt>
  <dd>A list of bucket names is returned with all other information stripped
      out. This is the default result type for this command.</dd>
  <dt><b>-result-type</b> <i>owner</i></dt>
  <dd>A list containing two elements is returned. The first element is the
      owner's ID, and the second is the owner's display name.</dd>
</dl>
</div>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt><b>S3::PutBucket</b> ?<b>-bucket</b> <i>bucketname</i>? ?<b>-blocking</b>
    <i>boolean</i>? ?<b>-acl</b>
    <i>{}|private|public-read|public-read-write|authenticated-read</i>?</dt>
  <dd>This command creates a bucket if it does not already exist. Bucket names
      are globally unique, so you may get a &quot;Forbidden&quot; error from
      Amazon even if you cannot see the bucket in <b>S3::ListAllMyBuckets</b>.
      See <b>S3::SuggestBucket</b> for ways to minimize this risk. The x-amz-acl
      header comes from the <b>-acl</b> option, or from <b>S3::Configure
      -default-acl</b> if not specified.</dd>
  <dt><b>S3::DeleteBucket</b> ?<b>-bucket</b> <i>bucketname</i>?
    ?<b>-blocking</b> <i>boolean</i>?</dt>
  <dd>This command deletes a bucket if it is empty and you have such permission.
      Note that Amazon's list of buckets is a global resource, requiring
      far-flung synchronization. If you delete a bucket, it may be quite a few
      minutes (or hours) before you can recreate it, yielding
      &quot;Conflict&quot; errors until then.</dd>
  <dt><b>S3::GetBucket</b> ?<b>-bucket</b> <i>bucketname</i>? ?<b>-blocking</b>
    <i>boolean</i>? ?<b>-parse-xml</b> <i>xmlstring</i>? ?<b>-max-count</b>
    <i>integer</i>? ?<b>-prefix</b> <i>prefixstring</i>? ?<b>-delimiter</b>
    <i>delimiterstring</i>? ?<b>-result-type</b>
    <i>REST|xml|pxml|names|dict</i>?</dt>
  <dd>This lists the contents of a bucket. That is, it returns a directory
      listing of resources within a bucket, rather than transfering any user
      data.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-bucket</b> <i>bucketname</i></dt>
  <dd>The standard bucket argument.</dd>
  <dt><b>-blocking</b> <i>boolean</i></dt>
  <dd>The standard blocking argument.</dd>
  <dt><b>-parse-xml</b> <i>xmlstring</i></dt>
  <dd>The standard parse-xml argument.</dd>
  <dt><b>-max-count</b> <i>integer</i></dt>
  <dd>If supplied, this is the most number of records to be returned. If not
      supplied, the code will iterate until all records have been found. Not
      compatible with -parse-xml. Note that if this is supplied, only one call
      to <b>S3::REST</b> will be made. Otherwise, enough calls will be made to
      exhaust the listing, buffering results in memory, so take care if you may
      have huge buckets.</dd>
  <dt><b>-prefix</b> <i>prefixstring</i></dt>
  <dd>If present, restricts listing to resources with a particular prefix. One
      leading / is stripped if present.</dd>
  <dt><b>-delimiter</b> <i>delimiterstring</i></dt>
  <dd>If present, specifies a delimiter for the listing. The presence of this
      will summarize multiple resources into one entry, as if S3 supported
      directories. See the Amazon documentation for details.</dd>
  <dt><b>-result-type</b> <i>REST|xml|pxml|names|dict</i></dt>
  <dd>This indicates the format of the return result of the command.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt>REST</dt>
  <dd>If <i>-max-count</i> is specified, the dictionary returned from
      <b>S3::REST</b> is returned. If <i>-max-count</i> is not specified, a list
      of all the dictionaries returned from the one or more calls to
      <b>S3::REST</b> is returned.</dd>
  <dt>xml</dt>
  <dd>If <i>-max-count</i> is specified, the body returned from <b>S3::REST</b>
      is returned. If <i>-max-count</i> is not specified, a list of all the
      bodies returned from the one or more calls to <b>S3::REST</b> is
    returned.</dd>
  <dt>pxml</dt>
  <dd>If <i>-max-count</i> is specified, the body returned from <b>S3::REST</b>
      is passed throught <b>xsxp::parse</b> and then returned. If
      <i>-max-count</i> is not specified, a list of all the bodies returned from
      the one or more calls to <b>S3::REST</b> are each passed through
      <b>xsxp::parse</b> and then returned.</dd>
  <dt>names</dt>
  <dd>Returns a list of all names found in either the Contents/Key fields or the
      CommonPrefixes/Prefix fields. If no <i>-delimiter</i> is specified and no
      <i>-max-count</i> is specified, this returns a list of all resources with
      the specified <i>-prefix</i>.</dd>
  <dt>dict</dt>
  <dd>Returns a dictionary. (Returns only one dictionary even if
      <i>-max-count</i> wasn't specified.) The keys of the dictionary are as
      follows:</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt>Name</dt>
  <dd>The name of the bucket (from the final call to <b>S3::REST</b>).</dd>
  <dt>Prefix</dt>
  <dd>From the final call to <b>S3::REST</b>.</dd>
  <dt>Marker</dt>
  <dd>From the final call to <b>S3::REST</b>.</dd>
  <dt>MaxKeys</dt>
  <dd>From the final call to <b>S3::REST</b>.</dd>
  <dt>IsTruncated</dt>
  <dd>From the final call to <b>S3::REST</b>, so always false if
      <i>-max-count</i> is not specified.</dd>
  <dt>NextMarker</dt>
  <dd>Always provided if IsTruncated is true, and calculated of Amazon does not
      provide it. May be empty if IsTruncated is false.</dd>
  <dt>Key</dt>
  <dd>A list of names of resources in the bucket matching the <i>-prefix</i> and
      <i>-delimiter</i> restrictions.</dd>
  <dt>LastModified</dt>
  <dd>A list of times of resources in the bucket, in the same order as Key, in
      the format returned by Amazon. (I.e., it is not parsed into a
      seconds-from-epoch.)</dd>
  <dt>ETag</dt>
  <dd>A list of entity tags (a.k.a. MD5 checksums) in the same order as
    Key.</dd>
  <dt>Size</dt>
  <dd>A list of sizes in bytes of the resources, in the same order as Key.</dd>
  <dt>Owner/ID</dt>
  <dd>A list of owners of the resources in the bucket, in the same order as
    Key.</dd>
  <dt>Owner/DisplayName</dt>
  <dd>A list of owners of the resources in the bucket, in the same order as Key.
      These are the display names.</dd>
  <dt>CommonPrefixes/Prefix</dt>
  <dd>A list of prefixes common to multiple entities. This is present only if
      <i>-delimiter</i> was supplied.</dd>
</dl>
</div>
</div>
</div>
<dl class="Bl-tag">
  <dt><b>S3::Put</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-resource</b>
    <i>resourcename</i> ?<b>-blocking</b> <i>boolean</i>? ?<b>-file</b>
    <i>filename</i>? ?<b>-content</b> <i>contentstring</i>? ?<b>-acl</b>
    <i>private|public-read|public-read-write|authenticated-read|calc|keep</i>?
    ?<b>-content-type</b> <i>contenttypestring</i>? ?<b>-x-amz-meta-*</b>
    <i>metadatatext</i>? ?<b>-compare</b> <i>comparemode</i>?</dt>
  <dd>This command sends data to a resource on Amazon's servers for storage,
      using the HTTP PUT command. It returns 0 if the <b>-compare</b> mode
      prevented the transfer, 1 if the transfer worked, or throws an error if
      the transfer was attempted but failed. Server 5XX errors and S3 socket
      errors are retried according to <b>S3:Configure -retries</b> settings
      before throwing an error; other errors throw immediately.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-bucket</b></dt>
  <dd>This specifies the bucket into which the resource will be written. Leading
      and/or trailing slashes are removed for you, as are spaces.</dd>
  <dt><b>-resource</b></dt>
  <dd>This is the full name of the resource within the bucket. A single leading
      slash is removed, but not a trailing slash. Spaces are not trimmed.</dd>
  <dt><b>-blocking</b></dt>
  <dd>The standard blocking flag.</dd>
  <dt><b>-file</b></dt>
  <dd>If this is specified, the <i>filename</i> must exist, must be readable,
      and must not be a special or directory file. [file size] must apply to it
      and must not change for the lifetime of the call. The default content-type
      is calculated based on the name and/or contents of the file. Specifying
      this is an error if <b>-content</b> is also specified, but at least one of
      <b>-file</b> or <b>-content</b> must be specified. (The file is allowed to
      not exist or not be readable if <b>-compare</b> <i>never</i> is
      specified.)</dd>
  <dt><b>-content</b></dt>
  <dd>If this is specified, the <i>contentstring</i> is sent as the body of the
      resource. The content-type defaults to
      &quot;application/octet-string&quot;. Only the low bytes are sent, so
      non-ASCII should use the appropriate encoding (such as [encoding convertto
      utf-8]) before passing it to this routine, if necessary. Specifying this
      is an error if <b>-file</b> is also specified, but at least one of
      <b>-file</b> or <b>-content</b> must be specified.</dd>
  <dt><b>-acl</b></dt>
  <dd>This defaults to <b>S3::Configure -default-acl</b> if not specified. It
      sets the x-amz-acl header on the PUT operation. If the value provided is
      <i>calc</i>, the x-amz-acl header is calculated based on the I/O
      permissions of the file to be uploaded; it is an error to specify
      <i>calc</i> and <b>-content</b>. If the value provided is <i>keep</i>, the
      acl of the resource is read before the PUT (or the default is used if the
      resource does not exist), then set back to what it was after the PUT (if
      it existed). An error will occur if the resource is successfully written
      but the kept ACL cannot be then applied. This should never happen.
      <i>Note:</i> <i>calc</i> is not currently fully implemented.</dd>
  <dt><b>-x-amz-meta-*</b></dt>
  <dd>If any header starts with &quot;-x-amz-meta-&quot;, its contents are added
      to the PUT command to be stored as metadata with the resource. Again, no
      encoding is performed, and the metadata should not contain characters like
      newlines, carriage returns, and so on. It is best to stick with simple
      ASCII strings, or to fix the library in several places.</dd>
  <dt><b>-content-type</b></dt>
  <dd>This overrides the content-type calculated by <b>-file</b> or sets the
      content-type for <b>-content</b>.</dd>
  <dt><b>-compare</b></dt>
  <dd>This is the standard compare mode argument. <b>S3::Put</b> returns 1 if
      the data was copied or 0 if the data was skipped due to the comparison
      mode so indicating it should be skipped.</dd>
</dl>
</div>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt><b>S3::Get</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-resource</b>
    <i>resourcename</i> ?<b>-blocking</b> <i>boolean</i>? ?<b>-compare</b>
    <i>comparemode</i>? ?<b>-file</b> <i>filename</i>? ?<b>-content</b>
    <i>contentvarname</i>? ?<b>-timestamp</b> <i>aws|now</i>? ?<b>-headers</b>
    <i>headervarname</i>?</dt>
  <dd>This command retrieves data from a resource on Amazon's S3 servers, using
      the HTTP GET command. It returns 0 if the <b>-compare</b> mode prevented
      the transfer, 1 if the transfer worked, or throws an error if the transfer
      was attempted but failed. Server 5XX errors and S3 socket errors are are
      retried according to <b>S3:Configure</b> settings before throwing an
      error; other errors throw immediately. Note that this is always
      authenticated as the user configured in via <b>S3::Configure
      -accesskeyid</b>. Use the Tcllib http for unauthenticated GETs.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-bucket</b></dt>
  <dd>This specifies the bucket from which the resource will be read. Leading
      and/or trailing slashes are removed for you, as are spaces.</dd>
  <dt><b>-resource</b></dt>
  <dd>This is the full name of the resource within the bucket. A single leading
      slash is removed, but not a trailing slash. Spaces are not trimmed.</dd>
  <dt><b>-blocking</b></dt>
  <dd>The standard blocking flag.</dd>
  <dt><b>-file</b></dt>
  <dd>If this is specified, the body of the resource will be read into this
      file, incrementally without pulling it entirely into memory first. The
      parent directory must already exist. If the file already exists, it must
      be writable. If an error is thrown part-way through the process and the
      file already existed, it may be clobbered. If an error is thrown part-way
      through the process and the file did not already exist, any partial bits
      will be deleted. Specifying this is an error if <b>-content</b> is also
      specified, but at least one of <b>-file</b> or <b>-content</b> must be
      specified.</dd>
  <dt><b>-timestamp</b></dt>
  <dd>This is only valid in conjunction with <b>-file</b>. It may be specified
      as <i>now</i> or <i>aws</i>. The default is <i>now</i>. If <i>now</i>, the
      file's modification date is left up to the system. If <i>aws</i>, the
      file's mtime is set to match the Last-Modified header on the resource,
      synchronizing the two appropriately for <b>-compare</b> <i>date</i> or
      <b>-compare</b> <i>newer</i>.</dd>
  <dt><b>-content</b></dt>
  <dd>If this is specified, the <i>contentvarname</i> is a variable in the
      caller's scope (not necessarily global) that receives the value of the
      body of the resource. No encoding is done, so if the resource (for
      example) represents a UTF-8 byte sequence, use [encoding convertfrom
      utf-8] to get a valid UTF-8 string. If this is specified, the
      <b>-compare</b> is ignored unless it is <i>never</i>, in which case no
      assignment to <i>contentvarname</i> is performed. Specifying this is an
      error if <b>-file</b> is also specified, but at least one of <b>-file</b>
      or <b>-content</b> must be specified.</dd>
  <dt><b>-compare</b></dt>
  <dd>This is the standard compare mode argument. <b>S3::Get</b> returns 1 if
      the data was copied or 0 if the data was skipped due to the comparison
      mode so indicating it should be skipped.</dd>
  <dt><b>-headers</b></dt>
  <dd>If this is specified, the headers resulting from the fetch are stored in
      the provided variable, as a dictionary. This will include content-type and
      x-amz-meta-* headers, as well as the usual HTTP headers, the x-amz-id
      debugging headers, and so on. If no file is fetched (due to
      <b>-compare</b> or other errors), no assignment to this variable is
      performed.</dd>
</dl>
</div>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt><b>S3::Head</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-resource</b>
    <i>resourcename</i> ?<b>-blocking</b> <i>boolean</i>? ?<b>-dict</b>
    <i>dictvarname</i>? ?<b>-headers</b> <i>headersvarname</i>? ?<b>-status</b>
    <i>statusvarname</i>?</dt>
  <dd>This command requests HEAD from the resource. It returns whether a 2XX
      code was returned as a result of the request, never throwing an S3 remote
      error. That is, if this returns 1, the resource exists and is accessible.
      If this returns 0, something went wrong, and the <b>-status</b> result can
      be consulted for details.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-bucket</b></dt>
  <dd>This specifies the bucket from which the resource will be read. Leading
      and/or trailing slashes are removed for you, as are spaces.</dd>
  <dt><b>-resource</b></dt>
  <dd>This is the full name of the resource within the bucket. A single leading
      slash is removed, but not a trailing slash. Spaces are not trimmed.</dd>
  <dt><b>-blocking</b></dt>
  <dd>The standard blocking flag.</dd>
  <dt><b>-dict</b></dt>
  <dd>If specified, the resulting dictionary from the <b>S3::REST</b> call is
      assigned to the indicated (not necessarily global) variable in the
      caller's scope.</dd>
  <dt><b>-headers</b></dt>
  <dd>If specified, the dictionary of headers from the result are assigned to
      the indicated (not necessarily global) variable in the caller's
    scope.</dd>
  <dt><b>-status</b></dt>
  <dd>If specified, the indicated (not necessarily global) variable in the
      caller's scope is assigned a 2-element list. The first element is the
      3-digit HTTP status code, while the second element is the HTTP message
      (such as &quot;OK&quot; or &quot;Forbidden&quot;).</dd>
</dl>
</div>
<dl class="Bl-tag">
  <dt><b>S3::GetAcl</b> ?<b>-blocking</b> <i>boolean</i>? ?<b>-bucket</b>
    <i>bucketname</i>? <b>-resource</b> <i>resourcename</i> ?<b>-result-type</b>
    <i>REST|xml|pxml</i>?</dt>
  <dd>This command gets the ACL of the indicated resource or throws an error if
      it is unavailable.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-blocking</b> <i>boolean</i></dt>
  <dd>See above for standard definition.</dd>
  <dt><b>-bucket</b></dt>
  <dd>This specifies the bucket from which the resource will be read. Leading
      and/or trailing slashes are removed for you, as are spaces.</dd>
  <dt><b>-resource</b></dt>
  <dd>This is the full name of the resource within the bucket. A single leading
      slash is removed, but not a trailing slash. Spaces are not trimmed.</dd>
  <dt><b>-parse-xml</b> <i>xml</i></dt>
  <dd>The XML from a previous GetACL can be passed in to be parsed into
      dictionary form. In this case, -result-type must be pxml or dict.</dd>
  <dt><b>-result-type</b> <i>REST</i></dt>
  <dd>The dictionary returned by <b>S3::REST</b> is the return value of
      <b>S3::GetAcl</b>. In this case, a non-2XX httpstatus will not throw an
      error.</dd>
  <dt><b>-result-type</b> <i>xml</i></dt>
  <dd>The raw XML of the body is returned as the result (with no encoding
      applied).</dd>
  <dt><b>-result-type</b> <i>pxml</i></dt>
  <dd>The XML of the body as parsed by <b>xsxp::parse</b> is returned.</dd>
  <dt><b>-result-type</b> <i>dict</i></dt>
  <dd>This fetches the ACL, parses it, and returns a dictionary of two elements.
    <p class="Pp">The first element has the key &quot;owner&quot; whose value is
        the canonical ID of the owner of the resource.</p>
    <p class="Pp">The second element has the key &quot;acl&quot; whose value is
        a dictionary. Each key in the dictionary is one of Amazon's permissions,
        namely &quot;READ&quot;, &quot;WRITE&quot;, &quot;READ_ACP&quot;,
        &quot;WRITE_ACP&quot;, or &quot;FULL_CONTROL&quot;. Each value of each
        key is a list of canonical IDs or group URLs that have that permission.
        Elements are not in the list in any particular order, and not all keys
        are necessarily present. Display names are not returned, as they are not
        especially useful; use pxml to obtain them if necessary.</p>
  </dd>
</dl>
</div>
<dl class="Bl-tag">
  <dt><b>S3::PutAcl</b> ?<b>-blocking</b> <i>boolean</i>? ?<b>-bucket</b>
    <i>bucketname</i>? <b>-resource</b> <i>resourcename</i> ?<b>-acl</b>
    <i>new-acl</i>?</dt>
  <dd>This sets the ACL on the indicated resource. It returns the XML written to
      the ACL, or throws an error if anything went wrong.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-blocking</b> <i>boolean</i></dt>
  <dd>See above for standard definition.</dd>
  <dt><b>-bucket</b></dt>
  <dd>This specifies the bucket from which the resource will be read. Leading
      and/or trailing slashes are removed for you, as are spaces.</dd>
  <dt><b>-resource</b></dt>
  <dd>This is the full name of the resource within the bucket. A single leading
      slash is removed, but not a trailing slash. Spaces are not trimmed.</dd>
  <dt><b>-owner</b></dt>
  <dd>If this is provided, it is assumed to match the owner of the resource.
      Otherwise, a GET may need to be issued against the resource to find the
      owner. If you already have the owner (such as from a call to
      <b>S3::GetAcl</b>, you can pass the value of the &quot;owner&quot; key as
      the value of this option, and it will be used in the construction of the
      XML.</dd>
  <dt><b>-acl</b></dt>
  <dd>If this option is specified, it provides the ACL the caller wishes to
      write to the resource. If this is not supplied or is empty, the value is
      taken from <b>S3::Configure -default-acl</b>. The ACL is written with a
      PUT to the ?acl resource.
    <p class="Pp">If the value passed to this option starts with
        &quot;&lt;&quot;, it is taken to be a body to be PUT to the ACL
        resource.</p>
    <p class="Pp">If the value matches one of the standard Amazon x-amz-acl
        headers (i.e., a canned access policy), that header is translated to XML
        and then applied. The canned access policies are private, public-read,
        public-read-write, and authenticated-read (in lower case).</p>
    <p class="Pp">Otherwise, the value is assumed to be a dictionary formatted
        as the &quot;acl&quot; sub-entry within the dict returns by
        <b>S3::GetAcl -result-type dict</b>. The proper XML is generated and
        applied to the resource. Note that a value containing &quot;//&quot; is
        assumed to be a group, a value containing &quot;@&quot; is assumed to be
        an AmazonCustomerByEmail, and otherwise the value is assumed to be a
        canonical Amazon ID.</p>
    <p class="Pp">Note that you cannot change the owner, so calling GetAcl on a
        resource owned by one user and applying it via PutAcl on a resource
        owned by another user may not do exactly what you expect.</p>
  </dd>
</dl>
</div>
<dl class="Bl-tag">
  <dt><b>S3::Delete</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-resource</b>
    <i>resourcename</i> ?<b>-blocking</b> <i>boolean</i>? ?<b>-status</b>
    <i>statusvar</i>?</dt>
  <dd>This command deletes the specified resource from the specified bucket. It
      returns 1 if the resource was deleted successfully, 0 otherwise. It
      returns 0 rather than throwing an S3 remote error.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-bucket</b></dt>
  <dd>This specifies the bucket from which the resource will be deleted. Leading
      and/or trailing slashes are removed for you, as are spaces.</dd>
  <dt><b>-resource</b></dt>
  <dd>This is the full name of the resource within the bucket. A single leading
      slash is removed, but not a trailing slash. Spaces are not trimmed.</dd>
  <dt><b>-blocking</b></dt>
  <dd>The standard blocking flag.</dd>
  <dt><b>-status</b></dt>
  <dd>If specified, the indicated (not necessarily global) variable in the
      caller's scope is set to a two-element list. The first element is the
      3-digit HTTP status code. The second element is the HTTP message (such as
      &quot;OK&quot; or &quot;Forbidden&quot;). Note that Amazon's DELETE result
      is 204 on success, that being the code indicating no content in the
      returned body.</dd>
</dl>
</div>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt><b>S3::Push</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-directory</b>
    <i>directoryname</i> ?<b>-prefix</b> <i>prefixstring</i>? ?<b>-compare</b>
    <i>comparemode</i>? ?<b>-x-amz-meta-*</b> <i>metastring</i>? ?<b>-acl</b>
    <i>aclcode</i>? ?<b>-delete</b> <i>boolean</i>? ?<b>-error</b>
    <i>throw|break|continue</i>? ?<b>-progress</b> <i>scriptprefix</i>?</dt>
  <dd>This synchronises a local directory with a remote bucket by pushing the
      differences using <b>S3::Put</b>. Note that if something has changed in
      the bucket but not locally, those changes could be lost. Thus, this is not
      a general two-way synchronization primitive. (See <b>S3::Sync</b> for
      that.) Note too that resource names are case sensitive, so changing the
      case of a file on a Windows machine may lead to otherwise-unnecessary
      transfers. Note that only regular files are considered, so devices, pipes,
      symlinks, and directories are not copied.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-bucket</b></dt>
  <dd>This names the bucket into which data will be pushed.</dd>
  <dt><b>-directory</b></dt>
  <dd>This names the local directory from which files will be taken. It must
      exist, be readable via [glob] and so on. If only some of the files therein
      are readable, <b>S3::Push</b> will PUT those files that are readable and
      return in its results the list of files that could not be opened.</dd>
  <dt><b>-prefix</b></dt>
  <dd>This names the prefix that will be added to all resources. That is, it is
      the remote equivalent of <b>-directory</b>. If it is not specified, the
      root of the bucket will be treated as the remote directory. An example may
      clarify.
    <pre>
S3::Push -bucket test -directory /tmp/xyz -prefix hello/world
    </pre>
    In this example, /tmp/xyz/pdq.html will be stored as
      http://s3.amazonaws.com/test/hello/world/pdq.html in Amazon's servers.
      Also, /tmp/xyz/abc/def/Hello will be stored as
      http://s3.amazonaws.com/test/hello/world/abc/def/Hello in Amazon's
      servers. Without the <b>-prefix</b> option, /tmp/xyz/pdq.html would be
      stored as http://s3.amazonaws.com/test/pdq.html.</dd>
  <dt><b>-blocking</b></dt>
  <dd>This is the standard blocking option.</dd>
  <dt><b>-compare</b></dt>
  <dd>If present, this is passed to each invocation of <b>S3::Put</b>.
      Naturally, <b>S3::Configure -default-compare</b> is used if this is not
      specified.</dd>
  <dt><b>-x-amz-meta-*</b></dt>
  <dd>If present, this is passed to each invocation of <b>S3::Put</b>. All
      copied files will have the same metadata.</dd>
  <dt><b>-acl</b></dt>
  <dd>If present, this is passed to each invocation of <b>S3::Put</b>.</dd>
  <dt><b>-delete</b></dt>
  <dd>This defaults to false. If true, resources in the destination that are not
      in the source directory are deleted with <b>S3::Delete</b>. Since only
      regular files are considered, the existance of a symlink, pipe, device, or
      directory in the local source will <i>not</i> prevent the deletion of a
      remote resource with a corresponding name.</dd>
  <dt><b>-error</b></dt>
  <dd>This controls the behavior of <b>S3::Push</b> in the event that
      <b>S3::Put</b> throws an error. Note that errors encountered on the local
      file system or in reading the list of resources in the remote bucket
      always throw errors. This option allows control over &quot;partial&quot;
      errors, when some files were copied and some were not. <b>S3::Delete</b>
      is always finished up, with errors simply recorded in the return
    result.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt>throw</dt>
  <dd>The error is rethrown with the same errorCode.</dd>
  <dt>break</dt>
  <dd>Processing stops without throwing an error, the error is recorded in the
      return value, and the command returns with a normal return. The calls to
      <b>S3::Delete</b> are not started.</dd>
  <dt>continue</dt>
  <dd>This is the default. Processing continues without throwing, recording the
      error in the return result, and resuming with the next file in the local
      directory to be copied.</dd>
</dl>
</div>
<dl class="Bl-tag">
  <dt><b>-progress</b></dt>
  <dd>If this is specified and the indicated script prefix is not empty, the
      indicated script prefix will be invoked several times in the caller's
      context with additional arguments at various points in the processing.
      This allows progress reporting without backgrounding. The provided prefix
      will be invoked with additional arguments, with the first additional
      argument indicating what part of the process is being reported on. The
      prefix is initially invoked with <i>args</i> as the first additional
      argument and a dictionary representing the normalized arguments to the
      <b>S3::Push</b> call as the second additional argument. Then the prefix is
      invoked with <i>local</i> as the first additional argument and a list of
      suffixes of the files to be considered as the second argument. Then the
      prefix is invoked with <i>remote</i> as the first additional argument and
      a list of suffixes existing in the remote bucket as the second additional
      argument. Then, for each file in the local list, the prefix will be
      invoked with <i>start</i> as the first additional argument and the common
      suffix as the second additional argument. When <b>S3::Put</b> returns for
      that file, the prefix will be invoked with <i>copy</i> as the first
      additional argument, the common suffix as the second additional argument,
      and a third argument that will be &quot;copied&quot; (if <b>S3::Put</b>
      sent the resource), &quot;skipped&quot; (if <b>S3::Put</b> decided not to
      based on <b>-compare</b>), or the errorCode that <b>S3::Put</b> threw due
      to unexpected errors (in which case the third argument is a list that
      starts with &quot;S3&quot;). When all files have been transfered, the
      prefix may be invoked zero or more times with <i>delete</i> as the first
      additional argument and the suffix of the resource being deleted as the
      second additional argument, with a third argument being either an empty
      string (if the delete worked) or the errorCode from <b>S3::Delete</b> if
      it failed. Finally, the prefix will be invoked with <i>finished</i> as the
      first additional argument and the return value as the second additional
      argument.</dd>
</dl>
</div>
The return result from this command is a dictionary. They keys are the suffixes
  (i.e., the common portion of the path after the <b>-directory</b> and
  <b>-prefix</b>), while the values are either &quot;copied&quot;,
  &quot;skipped&quot; (if <b>-compare</b> indicated not to copy the file), or
  the errorCode thrown by <b>S3::Put</b>, as appropriate. If <b>-delete</b> was
  true, there may also be entries for suffixes with the value
  &quot;deleted&quot; or &quot;notdeleted&quot;, indicating whether the
  attempted <b>S3::Delete</b> worked or not, respectively. There is one
  additional pair in the return result, whose key is the empty string and whose
  value is a nested dictionary. The keys of this nested dictionary include
  &quot;filescopied&quot; (the number of files successfully copied),
  &quot;bytescopied&quot; (the number of data bytes in the files copied,
  excluding headers, metadata, etc), &quot;compareskipped&quot; (the number of
  files not copied due to <b>-compare</b> mode), &quot;errorskipped&quot; (the
  number of files not copied due to thrown errors), &quot;filesdeleted&quot;
  (the number of resources deleted due to not having corresponding files
  locally, or 0 if <b>-delete</b> is false), and &quot;filesnotdeleted&quot;
  (the number of resources whose deletion was attempted but failed).
<p class="Pp">Note that this is currently implemented somewhat inefficiently. It
    fetches the bucket listing (including timestamps and eTags), then calls
    <b>S3::Put</b>, which uses HEAD to find the timestamps and eTags again.
    Correcting this with no API change is planned for a future upgrade.</p>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt><b>S3::Pull</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-directory</b>
    <i>directoryname</i> ?<b>-prefix</b> <i>prefixstring</i>? ?<b>-blocking</b>
    <i>boolean</i>? ?<b>-compare</b> <i>comparemode</i>? ?<b>-delete</b>
    <i>boolean</i>? ?<b>-timestamp</b> <i>aws|now</i>? ?<b>-error</b>
    <i>throw|break|continue</i>? ?<b>-progress</b> <i>scriptprefix</i>?</dt>
  <dd>This synchronises a remote bucket with a local directory by pulling the
      differences using <b>S3::Get</b> If something has been changed locally but
      not in the bucket, those difference may be lost. This is not a general
      two-way synchronization mechanism. (See <b>S3::Sync</b> for that.) This
      creates directories if needed; new directories are created with default
      permissions. Note that resource names are case sensitive, so changing the
      case of a file on a Windows machine may lead to otherwise-unnecessary
      transfers. Also, try not to store data in resources that end with a slash,
      or which are prefixes of resources that otherwise would start with a
      slash; i.e., don't use this if you store data in resources whose names
      have to be directories locally.
    <p class="Pp">Note that this is currently implemented somewhat
        inefficiently. It fetches the bucket listing (including timestamps and
        eTags), then calls <b>S3::Get</b>, which uses HEAD to find the
        timestamps and eTags again. Correcting this with no API change is
        planned for a future upgrade.</p>
  </dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-bucket</b></dt>
  <dd>This names the bucket from which data will be pulled.</dd>
  <dt><b>-directory</b></dt>
  <dd>This names the local directory into which files will be written It must
      exist, be readable via [glob], writable for file creation, and so on. If
      only some of the files therein are writable, <b>S3::Pull</b> will GET
      those files that are writable and return in its results the list of files
      that could not be opened.</dd>
  <dt><b>-prefix</b></dt>
  <dd>The prefix of resources that will be considered for retrieval. See
      <b>S3::Push</b> for more details, examples, etc. (Of course,
      <b>S3::Pull</b> reads rather than writes, but the prefix is treated
      similarly.)</dd>
  <dt><b>-blocking</b></dt>
  <dd>This is the standard blocking option.</dd>
  <dt><b>-compare</b></dt>
  <dd>This is passed to each invocation of <b>S3::Get</b> if provided.
      Naturally, <b>S3::Configure -default-compare</b> is used if this is not
      provided.</dd>
  <dt><b>-timestamp</b></dt>
  <dd>This is passed to each invocation of <b>S3::Get</b> if provided.</dd>
  <dt><b>-delete</b></dt>
  <dd>If this is specified and true, files that exist in the <b>-directory</b>
      that are not in the <b>-prefix</b> will be deleted after all resources
      have been copied. In addition, empty directories (other than the top-level
      <b>-directory</b>) will be deleted, as Amazon S3 has no concept of an
      empty directory.</dd>
  <dt><b>-error</b></dt>
  <dd>See <b>S3::Push</b> for a description of this option.</dd>
  <dt><b>-progress</b></dt>
  <dd>See <b>S3::Push</b> for a description of this option. It differs slightly
      in that local directories may be included with a trailing slash to
      indicate they are directories.</dd>
</dl>
</div>
The return value from this command is a dictionary. It is identical in form and
  meaning to the description of the return result of <b>S3::Push</b>. It differs
  only in that directories may be included, with a trailing slash in their name,
  if they are empty and get deleted.
<dl class="Bl-tag">
  <dt><b>S3::Toss</b> ?<b>-bucket</b> <i>bucketname</i>? <b>-prefix</b>
    <i>prefixstring</i> ?<b>-blocking</b> <i>boolean</i>? ?<b>-error</b>
    <i>throw|break|continue</i>? ?<b>-progress</b> <i>scriptprefix</i>?</dt>
  <dd>This deletes some or all resources within a bucket. It would be considered
      a &quot;recursive delete&quot; had Amazon implemented actual
    directories.</dd>
</dl>
<div class="Bd-indent">
<dl class="Bl-tag">
  <dt><b>-bucket</b></dt>
  <dd>The bucket from which resources will be deleted.</dd>
  <dt><b></b><b>-blocking</b></dt>
  <dd>The standard blocking option.</dd>
  <dt><b></b><b>-prefix</b></dt>
  <dd>The prefix for resources to be deleted. Any resource that starts with this
      string will be deleted. This is required. To delete everything in the
      bucket, pass an empty string for the prefix.</dd>
  <dt><b></b><b>-error</b></dt>
  <dd>If this is &quot;throw&quot;, <b>S3::Toss</b> rethrows any errors it
      encounters. If this is &quot;break&quot;, <b>S3::Toss</b> returns with a
      normal return after the first error, recording that error in the return
      result. If this is &quot;continue&quot;, which is the default,
      <b>S3::Toss</b> continues on and lists all errors in the return
    result.</dd>
  <dt><b></b><b>-progress</b></dt>
  <dd>If this is specified and not an empty string, the script prefix will be
      invoked several times in the context of the caller with additional
      arguments appended. Initially, it will be invoked with the first
      additional argument being <i>args</i> and the second being the processed
      list of arguments to <b>S3::Toss</b>. Then it is invoked with
      <i>remote</i> as the first additional argument and the list of suffixes in
      the bucket to be deleted as the second additional argument. Then it is
      invoked with the first additional argument being <i>delete</i> and the
      second additional argument being the suffix deleted and the third
      additional argument being &quot;deleted&quot; or &quot;notdeleted&quot;
      depending on whether <b>S3::Delete</b> threw an error. Finally, the script
      prefix is invoked with a first additional argument of &quot;finished&quot;
      and a second additional argument of the return value.</dd>
</dl>
</div>
The return value is a dictionary. The keys are the suffixes of files that
  <b>S3::Toss</b> attempted to delete, and whose values are either the string
  &quot;deleted&quot; or &quot;notdeleted&quot;. There is also one additional
  pair, whose key is the empty string and whose value is an embedded dictionary.
  The keys of this embedded dictionary include &quot;filesdeleted&quot; and
  &quot;filesnotdeleted&quot;, each of which has integer values.
</section>
<section class="Sh">
<h1 class="Sh" id="LIMITATIONS"><a class="permalink" href="#LIMITATIONS">LIMITATIONS</a></h1>
<ul class="Bl-bullet">
  <li>The pure-Tcl MD5 checking is slow. If you are processing files in the
      megabyte range, consider ensuring binary support is available.</li>
  <li>The commands <b>S3::Pull</b> and <b>S3::Push</b> fetch a directory listing
      which includes timestamps and MD5 hashes, then invoke <b>S3::Get</b> and
      <b>S3::Put</b>. If a complex <b>-compare</b> mode is specified,
      <b>S3::Get</b> and <b>S3::Put</b> will invoke a HEAD operation for each
      file to fetch timestamps and MD5 hashes of each resource again. It is
      expected that a future release of this package will solve this without any
      API changes.</li>
  <li>The commands <b>S3::Pull</b> and <b>S3::Push</b> fetch a directory listing
      without using <b>-max-count</b>. The entire directory is pulled into
      memory at once. For very large buckets, this could be a performance
      problem. The author, at this time, does not plan to change this behavior.
      Welcome to Open Source.</li>
  <li><b>S3::Sync</b> is neither designed nor implemented yet. The intention
      would be to keep changes synchronised, so changes could be made to both
      the bucket and the local directory and be merged by <b>S3::Sync</b>.</li>
  <li>Nor is <b>-compare</b> <i>calc</i> fully implemented. This is primarily
      due to Windows not providing a convenient method for distinguishing
      between local files that are &quot;public-read&quot; or
      &quot;public-read-write&quot;. Assistance figuring out TWAPI for this
      would be appreciated. The U**X semantics are difficult to map directly as
      well. See the source for details. Note that there are not tests for calc,
      since it isn't done yet.</li>
  <li>The HTTP processing is implemented within the library, rather than using a
      &quot;real&quot; HTTP package. Hence, multi-line headers are not (yet)
      handled correctly. Do not include carriage returns or linefeeds in
      x-amz-meta-* headers, content-type values, and so on. The author does not
      at this time expect to improve this.</li>
  <li>Internally, <b>S3::Push</b> and <b>S3::Pull</b> and <b>S3::Toss</b> are
      all very similar and should be refactored.</li>
  <li>The idea of using <b>-compare</b> <i>never</i> <b>-delete</b> <i>true</i>
      to delete files that have been deleted from one place but not the other
      yet not copying changed files is untested.</li>
</ul>
</section>
<section class="Sh">
<h1 class="Sh" id="USAGE_SUGGESTIONS"><a class="permalink" href="#USAGE_SUGGESTIONS">USAGE
  SUGGESTIONS</a></h1>
To fetch a &quot;directory&quot; out of a bucket, make changes, and store it
  back:
<pre>
file mkdir ./tempfiles
S3::Pull -bucket sample -prefix of/interest -directory ./tempfiles \
  -timestamp aws
do_my_process ./tempfiles other arguments
S3::Push -bucket sample -prefix of/interest -directory ./tempfiles \
  -compare newer -delete true
</pre>
<p class="Pp">To delete files locally that were deleted off of S3 but not
    otherwise update files:</p>
<pre>
S3::Pull -bucket sample -prefix of/interest -directory ./myfiles \
  -compare never -delete true
</pre>
</section>
<section class="Sh">
<h1 class="Sh" id="FUTURE_DEVELOPMENTS"><a class="permalink" href="#FUTURE_DEVELOPMENTS">FUTURE
  DEVELOPMENTS</a></h1>
The author intends to work on several additional projects related to this
  package, in addition to finishing the unfinished features.
<p class="Pp">First, a command-line program allowing browsing of buckets and
    transfer of files from shell scripts and command prompts is useful.</p>
<p class="Pp">Second, a GUI-based program allowing visual manipulation of bucket
    and resource trees not unlike Windows Explorer would be useful.</p>
<p class="Pp">Third, a command-line (and perhaps a GUI-based) program called
    &quot;OddJob&quot; that will use S3 to synchronize computation amongst
    multiple servers running OddJob. An S3 bucket will be set up with a number
    of scripts to run, and the OddJob program can be invoked on multiple
    machines to run scripts on all the machines, each moving on to the next
    unstarted task as it finishes each. This is still being designed, and it is
    intended primarily to be run on Amazon's Elastic Compute Cloud.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="BUGS,_IDEAS,_FEEDBACK"><a class="permalink" href="#BUGS,_IDEAS,_FEEDBACK">BUGS,
  IDEAS, FEEDBACK</a></h1>
This document, and the package it describes, will undoubtedly contain bugs and
  other problems. Please report such in the category <i>amazon-s3</i> of the
  <i>Tcllib SF Trackers</i> [http://sourceforge.net/tracker/?group_id=12883].
  Please also report any ideas for enhancements you may have for either package
  and/or documentation.
</section>
<section class="Sh">
<h1 class="Sh" id="KEYWORDS"><a class="permalink" href="#KEYWORDS">KEYWORDS</a></h1>
amazon, cloud, s3
</section>
<section class="Sh">
<h1 class="Sh" id="CATEGORY"><a class="permalink" href="#CATEGORY">CATEGORY</a></h1>
Networking
</section>
<section class="Sh">
<h1 class="Sh" id="COPYRIGHT"><a class="permalink" href="#COPYRIGHT">COPYRIGHT</a></h1>
<pre>
Copyright (c) Copyright 2006,2008 Darren New. All Rights Reserved. See LICENSE.TXT for terms.
</pre>
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">1.0.0</td>
    <td class="foot-os">amazon-s3</td>
  </tr>
</table>
</body>
</html>
