<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>

<style>
@media (prefers-color-scheme: dark) {
  body {
    background: #000;
    color: #d0d0d0;
  }

  a, a:visited {
    color: #1899eb;
  }
}
</style>

  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    .Nd, .Bf, .Op { display: inline; }
    .Pa, .Ad { font-style: italic; }
    .Ms { font-weight: bold; }
    .Bl-diag > dt { font-weight: bold; }
    code.Nm, .Fl, .Cm, .Ic, code.In, .Fd, .Fn, .Cd { font-weight: bold;
      font-family: inherit; }
  </style>
  <title>MPSCNNBinaryConvolution(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSCNNBinaryConvolution(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSCNNBinaryConvolution(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
<p class="Pp">MPSCNNBinaryConvolution</p>
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSCNNConvolution.h&gt;</p>
<p class="Pp">Inherits <b>MPSCNNKernel</b>.</p>
<p class="Pp">Inherited by <b>MPSCNNBinaryFullyConnected</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
<p class="Pp">(nonnull instancetype) -
    <b>initWithDevice:convolutionData:scaleValue:type:flags:</b>
  <br/>
  (nonnull instancetype) -
    <b>initWithDevice:convolutionData:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:</b>
  <br/>
  (nullable instancetype) - <b>initWithCoder:device:</b>
  <br/>
  (nonnull instancetype) - <b>initWithDevice:</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
<p class="Pp">NSUInteger <b>inputFeatureChannels</b>
  <br/>
  NSUInteger <b>outputFeatureChannels</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Additional_Inherited_Members"><a class="permalink" href="#Additional_Inherited_Members">Additional
  Inherited Members</a></h2>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
<p class="Pp">This depends on Metal.framework The <b>MPSCNNBinaryConvolution</b>
    specifies a convolution with binary weights and an input image using binary
    approximations. The <b>MPSCNNBinaryConvolution</b> optionally first
    binarizes the input image and then convolves the result with a set of
    binary-valued filters, each producing one feature map in the output image
    (which is a normal image)</p>
<p class="Pp">The output is computed as follows:</p>
<p class="Pp"></p>
<pre>out[i, x, y, c] = ( sum_{dx,dy,f} in[i,x+dx, y+dy, f] x B[c,dx,dy,f] )
<br/>
                    * scale[c] * beta[i,x,y] + bias[c], where
</pre>
<p class="Pp">the sum over dx,dy is over the spatial filter kernel window
    defined by 'kernelWidth' and 'KernelHeight', sum over 'f' is over the input
    feature channel indices within group, 'B' contains the binary weights,
    interpreted as {-1,1} or { 0, 1 } and scale[c] is the 'outputScaleTerms'
    array and bias is the 'outputBiasTerms' array. Above 'i' is the image index
    in batch the sum over input channels 'f' runs through the group indices.</p>
<p class="Pp">The convolution operator 'x' is defined by
    MPSCNNBinaryConvolutionType passed in at initialization time of the filter
  (</p>
<p class="Pp"><b>See also:</b></p>
<div class="Bd-indent">initWithDevice). In case 'type' =
  <b>MPSCNNBinaryConvolutionTypeBinaryWeights</b>, the input image is not
  binarized at all and the convolution is computed interpreting the weights as [
  0, 1 ] -&gt; { -1, 1 } with the given scaling terms. In case 'type' =
  <b>MPSCNNBinaryConvolutionTypeXNOR</b> the convolution is computed by first
  binarizing the input image using the sign function 'bin(x) = x &lt; 0 ? -1 :
  1' and the convolution multiplication is done with the XNOR-operator !(x ^ y)
  = delta_xy = { (x==y) ? 1 : 0 }, and scaled according to the optional scaling
  operations. Note that we output the values of the bitwise convolutions to
  interval { -1, 1 }, which means that the output of the XNOR-operator is scaled
  implicitly as follows: r = 2 * ( !(x ^ y) ) - 1 = { -1, 1 }. This means that
  for a dot-product of two 32-bit words the result is: r = 2 * popcount(!(x ^ y)
  ) - 32 = 32 - 2 * popcount( x ^ y ) = { -32, -30, ..., 30, 32 }. In case
  'type' = <b>MPSCNNBinaryConvolutionTypeAND</b> the convolution is computed by
  first binarizing the input image using the sign function 'bin(x) = x &lt; 0 ?
  -1 : 1' and the convolution multiplication is done with the AND-operator (x
  &amp; y) = delta_xy * delta_x1 = { (x==y==1) ? 1 : 0 }. and scaled according
  to the optional scaling operations. Note that we output the values of the
  AND-operation is assumed to lie in { 0, 1 } interval and hence no more
  implicit scaling takes place. This means that for a dot-product of two 32-bit
  words the result is: r = popcount(x &amp; y) = { 0, ..., 31, 32 }.</div>
<p class="Pp">The input data can be pre-offset and scaled by providing the
    'inputBiasTerms' and 'inputScaleTerms' parameters for the initialization
    functions and this can be used for example to accomplish batch normalization
    of the data. The scaling of input values happens before possible beta-image
    computation.</p>
<p class="Pp">The parameter 'beta' above is an optional image which is used to
    compute scaling factors for each spatial position and image index. For the
    XNOR-Net based networks this is computed as follows: beta[i,x,y] =
    sum_{dx,dy} <b>A</b>[i, x+dx, y+dy] / (kx * ky), where (dx,dy) are summed
    over the convolution filter window [ -kx/2, (kx-1)/2], [ -ky/2, (ky-1)/2 ]
    and <b>A</b>[i,x,y] = sum_{c} abs( in[i,x,y,c] ) / Nc, where 'in' is the
    original input image (in full precision) and Nc is the number of input
    channels in the input image. Parameter 'beta' is not passed as input and to
    enable beta-scaling the user can provide
    'MPSCNNBinaryConvolutionFlagsUseBetaScaling' in the flags parameter in the
    initialization functions.</p>
<p class="Pp">Finally the normal activation neuron is applied and the result is
    written to the output image.</p>
<p class="Pp">NOTE: <b>MPSCNNBinaryConvolution</b> does not currently support
    groups &gt; 1.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- (nullable instancetype) <b>initWithCoder:</b> (NSCoder
  *__nonnull) aDecoder(nonnull id&lt; MTLDevice &gt;) device</h2>
<p class="Pp"><b>NSSecureCoding</b> compatability While the standard
    NSSecureCoding/NSCoding method -initWithCoder: should work, since the file
    can't know which device your data is allocated on, we have to guess and may
    guess incorrectly. To avoid that problem, use initWithCoder:device
  instead.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>aDecoder</i> The NSCoder subclass with your serialized
  <b>MPSKernel</b>
<br/>
<i>device</i> The MTLDevice on which to make the <b>MPSKernel</b></div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> new <b>MPSKernel</b> object, or nil if
  failure.</div>
<p class="Pp">Reimplemented from <b>MPSCNNKernel</b>.</p>
<p class="Pp">Reimplemented in <b>MPSCNNBinaryFullyConnected</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) initWithDevice: (nonnull id&lt;
  MTLDevice &gt;) device</h2>
<p class="Pp">Standard init with default properties per filter type</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device that the filter will be used on.
  May not be NULL.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> pointer to the newly initialized object. This
  will fail, returning nil if the device is not supported. Devices must be
  MTLFeatureSet_iOS_GPUFamily2_v1 or later.</div>
<p class="Pp">Reimplemented from <b>MPSCNNKernel</b>.</p>
<p class="Pp">Reimplemented in <b>MPSCNNBinaryFullyConnected</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt;
  MTLDevice &gt;) device(nonnull id&lt; <b>MPSCNNConvolutionDataSource</b> &gt;)
  convolutionData(const float *__nullable) outputBiasTerms(const float
  *__nullable) outputScaleTerms(const float *__nullable) inputBiasTerms(const
  float *__nullable) inputScaleTerms(<b>MPSCNNBinaryConvolutionType</b>)
  type(<b>MPSCNNBinaryConvolutionFlags</b>) flags</h2>
<p class="Pp">Initializes a binary convolution kernel with binary weights as
    well as both pre and post scaling terms.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The MTLDevice on which this
  <b>MPSCNNBinaryConvolution</b> filter will be used
<br/>
<i>convolutionData</i> <b>A</b> pointer to a object that conforms to the
  <b>MPSCNNConvolutionDataSource</b> protocol. The
  <b>MPSCNNConvolutionDataSource</b> protocol declares the methods that an
  instance of <b>MPSCNNBinaryConvolution</b> uses to obtain the weights and the
  convolution descriptor. Each entry in the convolutionData:weights array is a
  32-bit unsigned integer value and each bit represents one filter weight (given
  in machine byte order). The featurechannel indices increase from the least
  significant bit within the 32-bits. The number of entries is = ceil(
  inputFeatureChannels/32.0 ) * outputFeatureChannels * kernelHeight *
  kernelWidth The layout of filter weight is so that it can be reinterpreted as
  a 4D tensor (array) weight[ outputChannels ][ kernelHeight ][ kernelWidth ][
  ceil( inputChannels / 32.0 ) ] (The ordering of the reduction from 4D tensor
  to 1D is per C convention. The index based on inputchannels varies most
  rapidly, followed by kernelWidth, then kernelHeight and finally outputChannels
  varies least rapidly.)
<br/>
<i>outputBiasTerms</i> <b>A</b> pointer to bias terms to be applied to the
  convolution output. Each entry is a float value. The number of entries is =
  numberOfOutputFeatureMaps. If nil then 0.0 is used for bias. The values stored
  in the pointer are copied in and the array can be freed after this function
  returns.
<br/>
<i>outputScaleTerms</i> <b>A</b> pointer to scale terms to be applied to binary
  convolution results per output feature channel. Each entry is a float value.
  The number of entries is = numberOfOutputFeatureMaps. If nil then 1.0 is used.
  The values stored in the pointer are copied in and the array can be freed
  after this function returns.
<br/>
<i>inputBiasTerms</i> <b>A</b> pointer to offset terms to be applied to the
  input before convolution and before input scaling. Each entry is a float
  value. The number of entries is 'inputFeatureChannels'. If NULL then 0.0 is
  used for bias. The values stored in the pointer are copied in and the array
  can be freed after this function returns.
<br/>
<i>inputScaleTerms</i> <b>A</b> pointer to scale terms to be applied to the
  input before convolution, but after input biasing. Each entry is a float
  value. The number of entries is 'inputFeatureChannels'. If nil then 1.0 is
  used. The values stored in the pointer are copied in and the array can be
  freed after this function returns.
<br/>
<i>type</i> What kind of binarization strategy is to be used.
<br/>
<i>flags</i> See documentation above and documentation of
  MPSCNNBinaryConvolutionFlags.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSCNNBinaryConvolution</b> object or
  nil, if failure.</div>
<p class="Pp">Reimplemented in <b>MPSCNNBinaryFullyConnected</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt;
  MTLDevice &gt;) device(nonnull id&lt; <b>MPSCNNConvolutionDataSource</b> &gt;)
  convolutionData(float) scaleValue(<b>MPSCNNBinaryConvolutionType</b>)
  type(<b>MPSCNNBinaryConvolutionFlags</b>) flags</h2>
<p class="Pp">Initializes a binary convolution kernel with binary weights and a
    single scaling term.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The MTLDevice on which this
  <b>MPSCNNBinaryConvolution</b> filter will be used
<br/>
<i>convolutionData</i> <b>A</b> pointer to a object that conforms to the
  <b>MPSCNNConvolutionDataSource</b> protocol. The
  <b>MPSCNNConvolutionDataSource</b> protocol declares the methods that an
  instance of <b>MPSCNNBinaryConvolution</b> uses to obtain the weights and bias
  terms as well as the convolution descriptor. Each entry in the
  convolutionData:weights array is a 32-bit unsigned integer value and each bit
  represents one filter weight (given in machine byte order). The featurechannel
  indices increase from the least significant bit within the 32-bits. The number
  of entries is = ceil( inputFeatureChannels/32.0 ) * outputFeatureChannels *
  kernelHeight * kernelWidth The layout of filter weight is so that it can be
  reinterpreted as a 4D tensor (array) weight[ outputChannels ][ kernelHeight ][
  kernelWidth ][ ceil( inputChannels / 32.0 ) ] (The ordering of the reduction
  from 4D tensor to 1D is per C convention. The index based on inputchannels
  varies most rapidly, followed by kernelWidth, then kernelHeight and finally
  outputChannels varies least rapidly.)
<br/>
<i>scaleValue</i> <b>A</b> floating point value used to scale the entire
  convolution.
<br/>
<i>type</i> What kind of binarization strategy is to be used.
<br/>
<i>flags</i> See documentation above and documentation of
  MPSCNNBinaryConvolutionFlags.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSCNNBinaryConvolution</b> object or
  nil, if failure.</div>
<p class="Pp">Reimplemented in <b>MPSCNNBinaryFullyConnected</b>.</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- (NSUInteger) inputFeatureChannels [read]<b>, [nonatomic]</b>,
  [assign]<b></b></h2>
</section>
<section class="Ss">
<h2 class="Ss">- outputFeatureChannels [read]<b>, [nonatomic]</b>,
  [assign]<b></b></h2>
<p class="Pp">The number of feature channels per pixel in the output image.</p>
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
<p class="Pp">Generated automatically by Doxygen for
    MetalPerformanceShaders.framework from the source code.</p>
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
