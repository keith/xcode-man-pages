<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>

<style>
@media (prefers-color-scheme: dark) {
  body {
    background: #000;
    color: #d0d0d0;
  }

  a, a:visited {
    color: #1899eb;
  }
}
</style>

  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
    div.Nd, div.Bf, div.Op { display: inline; }
    span.Pa, span.Ad { font-style: italic; }
    span.Ms { font-weight: bold; }
    dl.Bl-diag > dt { font-weight: bold; }
    code.Nm, code.Fl, code.Cm, code.Ic, code.In, code.Fd, code.Fn,
    code.Cd { font-weight: bold; font-family: inherit; }
  </style>
  <title>MPSCNNKernel(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSCNNKernel(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSCNNKernel(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
MPSCNNKernel
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSCNNKernel.h&gt;</p>
<p class="Pp">Inherits <b>MPSKernel</b>.</p>
<p class="Pp">Inherited by <b>MPSCNNBatchNormalization</b>,
    <b>MPSCNNBatchNormalizationStatistics</b>, <b>MPSCNNBinaryConvolution</b>,
    <b>MPSCNNConvolution</b>, <b>MPSCNNConvolutionTranspose</b>,
    <b>MPSCNNCrossChannelNormalization</b>, <b>MPSCNNDropout</b>,
    <b>MPSCNNInstanceNormalization</b>, <b>MPSCNNLocalContrastNormalization</b>,
    <b>MPSCNNLogSoftMax</b>, <b>MPSCNNLoss</b>, <b>MPSCNNNeuron</b>,
    <b>MPSCNNPooling</b>, <b>MPSCNNSoftMax</b>,
    <b>MPSCNNSpatialNormalization</b>, <b>MPSCNNUpsampling</b>,
    <b>MPSCNNYOLOLoss</b>, <b>MPSNNCropAndResizeBilinear</b>,
    <b>MPSNNReduceUnary</b>, <b>MPSNNReshape</b>, <b>MPSNNResizeBilinear</b>,
    <b>MPSNNSlice</b>, and <b>MPSRNNImageInferenceLayer</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
(nonnull instancetype) - <b>initWithDevice:</b>
<br/>
(nullable instancetype) - <b>initWithCoder:device:</b>
<br/>
(void) - <b>encodeToCommandBuffer:sourceImage:destinationImage:</b>
<br/>
(void) -
  <b>encodeToCommandBuffer:sourceImage:destinationState:destinationImage:</b>
<br/>
(void) - <b>encodeBatchToCommandBuffer:sourceImages:destinationImages:</b>
<br/>
(void) -
  <b>encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationImages:</b>
<br/>
(<b>MPSImage</b> *__nonnull) - <b>encodeToCommandBuffer:sourceImage:</b>
<br/>
(<b>MPSImage</b> *__nonnull) -
  <b>encodeToCommandBuffer:sourceImage:destinationState:destinationStateIsTemporary:</b>
<br/>
(<b>MPSImageBatch</b> *__nonnull) -
  <b>encodeBatchToCommandBuffer:sourceImages:</b>
<br/>
(<b>MPSImageBatch</b> *__nonnull) -
  <b>encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:</b>
<br/>
(<b>MPSState</b> *__nullable) -
  <b>resultStateForSourceImage:sourceStates:destinationImage:</b>
<br/>
(<b>MPSStateBatch</b> *__nullable) -
  <b>resultStateBatchForSourceImage:sourceStates:destinationImage:</b>
<br/>
(<b>MPSState</b> *__nullable) -
  <b>temporaryResultStateForCommandBuffer:sourceImage:sourceStates:destinationImage:</b>
<br/>
(<b>MPSStateBatch</b> *__nullable) -
  <b>temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:destinationImage:</b>
<br/>
(BOOL) - <b>isResultStateReusedAcrossBatch</b>
<br/>
(BOOL) - <b>appendBatchBarrier</b>
<br/>
(<b>MPSImageDescriptor</b> *__nonnull) -
  <b>destinationImageDescriptorForSourceImages:sourceStates:</b>
<br/>
<br/>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
<b>MPSOffset</b> <b>offset</b>
<br/>
MTLRegion <b>clipRect</b>
<br/>
NSUInteger <b>destinationFeatureChannelOffset</b>
<br/>
NSUInteger <b>sourceFeatureChannelOffset</b>
<br/>
NSUInteger <b>sourceFeatureChannelMaxCount</b>
<br/>
<b>MPSImageEdgeMode</b> <b>edgeMode</b>
<br/>
NSUInteger <b>kernelWidth</b>
<br/>
NSUInteger <b>kernelHeight</b>
<br/>
NSUInteger <b>strideInPixelsX</b>
<br/>
NSUInteger <b>strideInPixelsY</b>
<br/>
NSUInteger <b>dilationRateX</b>
<br/>
NSUInteger <b>dilationRateY</b>
<br/>
BOOL <b>isBackwards</b>
<br/>
BOOL BOOL <b>isStateModified</b>
<br/>
id&lt; <b>MPSNNPadding</b> &gt; <b>padding</b>
<br/>
id&lt; <b>MPSNNPadding</b> &gt; id&lt; MPSImageAllocator &gt;
  <b>destinationImageAllocator</b>
<br/>
<br/>
</section>
<section class="Ss">
<h2 class="Ss" id="Additional_Inherited_Members"><a class="permalink" href="#Additional_Inherited_Members">Additional
  Inherited Members</a></h2>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
This depends on Metal.framework Describes a convolution neural network kernel.
  <b>A</b> <b>MPSCNNKernel</b> consumes one <b>MPSImage</b> and produces one
  <b>MPSImage</b>.
<p class="Pp"></p>
<pre>
        The region overwritten in the destination MPSImage is described
        by the clipRect.  The top left corner of the region consumed (ignoring
        adjustments for filter size -- e.g. convolution filter size) is given
        by the offset. The size of the region consumed is a function of the
        clipRect size and any subsampling caused by pixel strides at work,
        e.g. MPSCNNPooling.strideInPixelsX/Y.  Where the offset + clipRect
        would cause a {x,y} pixel address not in the image to be read, the
        edgeMode is used to determine what value to read there.
        The Z/depth component of the offset, clipRect.origin and clipRect.size
        indexes which images to use. If the MPSImage contains only a single image
        then these should be offset.z = 0, clipRect.origin.z = 0
        and clipRect.size.depth = 1. If the MPSImage contains multiple images,
        clipRect.size.depth refers to number of images to process. Both source
        and destination MPSImages must have at least this many images. offset.z
        refers to starting source image index. Thus offset.z + clipRect.size.depth must
        be &lt;= source.numberOfImages. Similarly, clipRect.origin.z refers to starting
        image index in destination. So clipRect.origin.z + clipRect.size.depth must be
        &lt;= destination.numberOfImage.
        destinationFeatureChannelOffset property can be used to control where the MPSKernel will
        start writing in feature channel dimension. For example, if the destination image has
        64 channels, and MPSKernel outputs 32 channels, by default channels 0-31 of destination
        will be populated by MPSKernel. But if we want this MPSKernel to populate channel 32-63
        of the destination, we can set destinationFeatureChannelOffset = 32.
        A good example of this is concat (concatenation) operation in Tensor Flow. Suppose
        we have a src = w x h x Ni which goes through CNNConvolution_0 which produces
        output O0 = w x h x N0 and CNNConvolution_1 which produces output O1 = w x h x N1 followed
        by concatenation which produces O = w x h x (N0 + N1). We can achieve this by creating
        an MPSImage with dimensions O = w x h x (N0 + N1) and using this as destination of
        both convolutions as follows
            CNNConvolution0: destinationFeatureChannelOffset = 0, this will output N0 channels starting at
                             channel 0 of destination thus populating [0,N0-1] channels.
            CNNConvolution1: destinationFeatureChannelOffset = N0, this will output N1 channels starting at
                             channel N0 of destination thus populating [N0,N0+N1-1] channels.
        A MPSCNNKernel can be saved to disk / network using NSCoders such as NSKeyedArchiver. 
        When decoding, the system default MTLDevice will be chosen unless the NSCoder adopts 
        the &lt;MPSDeviceProvider&gt; protocol.  To accomplish this you will likely need to subclass your
        unarchiver to add this method.
</pre>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="_-_(BOOL)_appendBatchBarrier"><a class="permalink" href="#_-_(BOOL)_appendBatchBarrier">-
  (BOOL) appendBatchBarrier </a></h2>
Returns YES if the filter must be run over the entire batch before its results
  may be used Nearly all filters do not need to see the entire batch all at once
  and can operate correctly with partial batches. This allows the graph to
  strip-mine the problem, processing the graph top to bottom on a subset of the
  batch at a time, dramatically reducing memory usage. As the full nominal
  working set for a graph is often so large that it may not fit in memory,
  sub-batching may be required forward progress.
<p class="Pp">Batch normalization statistics on the other hand must complete the
    batch before the statistics may be used to normalize the images in the batch
    in the ensuing normalization filter. Consequently, batch normalization
    statistics requests the graph insert a batch barrier following it by
    returning YES from -appendBatchBarrier. This tells the graph to complete the
    batch before any dependent filters can start. Note that the filter itself
    may still be subject to sub-batching in its operation. All filters must be
    able to function without seeing the entire batch in a single -encode call.
    Carry over state that is accumulated across sub-batches is commonly carried
    in a shared <b>MPSState</b> containing a MTLBuffer. See
    -isResultStateReusedAcrossBatch.</p>
<p class="Pp">Caution: on most supported devices, the working set may be so
    large that the graph may be forced to throw away and recalculate most
    intermediate images in cases where strip-mining can not occur because
    -appendBatchBarrier returns YES. <b>A</b> single batch barrier can commonly
    cause a memory size increase and/or performance reduction by many fold over
    the entire graph. Filters of this variety should be avoided.</p>
<p class="Pp">Default: NO</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSImageDescriptor_fP*__nonnull)_destinationImageDescriptorForSourceImages:_(NSArray___fBMPSImage_fP_*___*__nonnull)_sourceImages(NSArray___fBMPSState_fP_*___*__nullable)_sourceStates"><a class="permalink" href="#_-_(_fBMPSImageDescriptor_fP*__nonnull)_destinationImageDescriptorForSourceImages:_(NSArray___fBMPSImage_fP_*___*__nonnull)_sourceImages(NSArray___fBMPSState_fP_*___*__nullable)_sourceStates">-
  (<b>MPSImageDescriptor</b>*__nonnull)
  destinationImageDescriptorForSourceImages: (NSArray&lt; <b>MPSImage</b> * &gt;
  *__nonnull) sourceImages(NSArray&lt; <b>MPSState</b> * &gt; *__nullable)
  sourceStates</a></h2>
Get a suggested destination image descriptor for a source image Your application
  is certainly free to pass in any destinationImage it likes to
  encodeToCommandBuffer:sourceImage:destinationImage, within reason. This is the
  basic design for iOS 10. This method is therefore not required.
<p class="Pp">However, calculating the <b>MPSImage</b> size and
    <b>MPSCNNKernel</b> properties for each filter can be tedious and
    complicated work, so this method is made available to automate the process.
    The application may modify the properties of the descriptor before a
    <b>MPSImage</b> is made from it, so long as the choice is sensible for the
    kernel in question. Please see individual kernel descriptions for
    restrictions.</p>
<p class="Pp">The expected timeline for use is as follows:</p>
<p class="Pp">1) This method is called: a) The default MPS padding calculation
    is applied. It uses the MPSNNPaddingMethod of the .padding property to
    provide a consistent addressing scheme over the graph. It creates the
    <b>MPSImageDescriptor</b> and adjusts the .offset property of the
    MPSNNKernel. When using a <b>MPSNNGraph</b>, the padding is set using the
    <b>MPSNNFilterNode</b> as a proxy.</p>
<p class="Pp">b) This method may be overridden by <b>MPSCNNKernel</b> subclass
    to achieve any customization appropriate to the object type.</p>
<p class="Pp">c) Source states are then applied in order. These may modify the
    descriptor and may update other object properties. See:
    -destinationImageDescriptorForSourceImages:sourceStates:
    forKernel:suggestedDescriptor: This is the typical way in which MPS may
    attempt to influence the operation of its kernels.</p>
<p class="Pp">d) If the .padding property has a custom padding policy method of
    the same name, it is called. Similarly, it may also adjust the descriptor
    and any <b>MPSCNNKernel</b> properties. This is the typical way in which
    your application may attempt to influence the operation of the MPS
  kernels.</p>
<p class="Pp">2) <b>A</b> result is returned from this method and the caller may
    further adjust the descriptor and kernel properties directly.</p>
<p class="Pp">3) The caller uses the descriptor to make a new <b>MPSImage</b> to
    use as the destination image for the -encode call in step 5.</p>
<p class="Pp">4) The caller calls
    -resultStateForSourceImage:sourceStates:destinationImage: to make any result
    states needed for the kernel. If there isn't one, it will return nil.
    <b>A</b> variant is available to return a temporary state instead.</p>
<p class="Pp">5) a -encode method is called to encode the kernel.</p>
<p class="Pp">The entire process 1-5 is more simply achieved by just calling an
    -encode... method that returns a <b>MPSImage</b> out the left hand sid of
    the method. Simpler still, use the <b>MPSNNGraph</b> to coordinate the
    entire process from end to end. Opportunities to influence the process are
    of course reduced, as (2) is no longer possible with either method. Your
    application may opt to use the five step method if it requires greater
    customization as described, or if it would like to estimate storage in
    advance based on the sum of MPSImageDescriptors before processing a graph.
    Storage estimation is done by using the <b>MPSImageDescriptor</b> to create
    a <b>MPSImage</b> (without passing it a texture), and then call
    -resourceSize. As long as the <b>MPSImage</b> is not used in an encode call
    and the .texture property is not invoked, the underlying MTLTexture is not
    created.</p>
<p class="Pp">No destination state or destination image is provided as an
    argument to this function because it is expected they will be made /
    configured after this is called. This method is expected to auto-configure
    important object properties that may be needed in the ensuing destination
    image and state creation steps.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>sourceImages</i> <b>A</b> array of source images that
  will be passed into the -encode call Since <b>MPSCNNKernel</b> is a unary
  kernel, it is an array of length 1.
<br/>
<i>sourceStates</i> An optional array of source states that will be passed into
  the -encode call</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">an image descriptor allocated on the autorelease
  pool</div>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSImageBatch_fP_*___nonnull)_encodeBatchToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImages"><a class="permalink" href="#_-_(_fBMPSImageBatch_fP_*___nonnull)_encodeBatchToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImages">-
  (<b>MPSImageBatch</b> * __nonnull) encodeBatchToCommandBuffer: (nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSImageBatch</b> *__nonnull)
  sourceImages</a></h2>
Encode a <b>MPSCNNKernel</b> into a command Buffer. Create a texture to hold the
  result and return it. In the first iteration on this method,
  encodeToCommandBuffer:sourceImage:destinationImage: some work was left for the
  developer to do in the form of correctly setting the offset property and
  sizing the result buffer. With the introduction of the padding policy (see
  padding property) the filter can do this work itself. If you would like to
  have some input into what sort of <b>MPSImage</b> (e.g. temporary vs. regular)
  or what size it is or where it is allocated, you may set the
  destinationImageAllocator to allocate the image yourself.
<p class="Pp">This method uses the <b>MPSNNPadding</b> padding property to
    figure out how to size the result image and to set the offset property. See
    discussion in <b>MPSNeuralNetworkTypes.h</b>. All images in a batch must
    have <b>MPSImage.numberOfImages</b> = 1.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The command buffer
<br/>
<i>sourceImages</i> <b>A</b> MPSImages to use as the source images for the
  filter.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">An array of MPSImages or MPSTemporaryImages allocated per
  the destinationImageAllocator containing the output of the graph. The offset
  property will be adjusted to reflect the offset used during the encode. The
  returned images will be automatically released when the command buffer
  completes. If you want to keep them around for longer, retain the
  images.</div>
<p class="Pp">Reimplemented in <b>MPSCNNBatchNormalizationStatistics</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeBatchToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(_fBMPSImageBatch_fP_*__nonnull)_destinationImages"><a class="permalink" href="#_-_(void)_encodeBatchToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(_fBMPSImageBatch_fP_*__nonnull)_destinationImages">-
  (void) encodeBatchToCommandBuffer: (nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSImageBatch</b> *__nonnull)
  sourceImages(<b>MPSImageBatch</b> *__nonnull) destinationImages</a></h2>
Encode a <b>MPSCNNKernel</b> into a command Buffer. The operation shall proceed
  out-of-place. This is the older style of encode which reads the offset,
  doesn't change it, and ignores the padding method.
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded filter
<br/>
<i>sourceImages</i> <b>A</b> valid <b>MPSImage</b> object containing the source
  images.
<br/>
<i>destinationImages</i> <b>A</b> valid <b>MPSImage</b> to be overwritten by
  result images. destinationImages may not alias sourceImages, even at different
  indices.</div>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeBatchToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(_fBMPSStateBatch_fP_*__nullable)_destinationStates(_fBMPSImageBatch_fP_*__nonnull)_destinationImages"><a class="permalink" href="#_-_(void)_encodeBatchToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(_fBMPSStateBatch_fP_*__nullable)_destinationStates(_fBMPSImageBatch_fP_*__nonnull)_destinationImages">-
  (void) encodeBatchToCommandBuffer: (nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSImageBatch</b> *__nonnull)
  sourceImages(<b>MPSStateBatch</b> *__nullable)
  destinationStates(<b>MPSImageBatch</b> *__nonnull) destinationImages</a></h2>
Encode a <b>MPSCNNKernel</b> with a destination state into a command Buffer.
  This is typically used during training. The state is commonly a
  <b>MPSNNGradientState</b>. Please see
  -resultStateForSourceImages:SourceStates:destinationImage and batch+temporary
  variants.
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded filter
<br/>
<i>sourceImages</i> <b>A</b> valid <b>MPSImage</b> object containing the source
  images.
<br/>
<i>destinationStates</i> <b>A</b> list of states to be overwritten by results
<br/>
<i>destinationImages</i> <b>A</b> valid <b>MPSImage</b> to be overwritten by
  result images. destinationImages may not alias sourceImages, even at different
  indices.</div>
<p class="Pp">Reimplemented in <b>MPSCNNBatchNormalization</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSImageBatch_fP_*___nonnull)_encodeBatchToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(__autoreleasing__fBMPSStateBatch_fP_*__nullable_*__nonnull)_outStates(BOOL)_isTemporary"><a class="permalink" href="#_-_(_fBMPSImageBatch_fP_*___nonnull)_encodeBatchToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImages(__autoreleasing__fBMPSStateBatch_fP_*__nullable_*__nonnull)_outStates(BOOL)_isTemporary">-
  (<b>MPSImageBatch</b> * __nonnull) encodeBatchToCommandBuffer: (nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSImageBatch</b> *__nonnull)
  sourceImages(__autoreleasing <b>MPSStateBatch</b> *__nullable *__nonnull)
  outStates(BOOL) isTemporary</a></h2>
Encode a <b>MPSCNNKernel</b> into a command Buffer. Create a MPSImageBatch and
  MPSStateBatch to hold the results and return them. In the first iteration on
  this method, encodeToCommandBuffer:sourceImage:destinationImage: some work was
  left for the developer to do in the form of correctly setting the offset
  property and sizing the result buffer. With the introduction of the padding
  policy (see padding property) the filter can do this work itself. If you would
  like to have some input into what sort of <b>MPSImage</b> (e.g. temporary vs.
  regular) or what size it is or where it is allocated, you may set the
  destinationImageAllocator to allocate the image yourself.
<p class="Pp">This method uses the <b>MPSNNPadding</b> padding property to
    figure out how to size the result image and to set the offset property. See
    discussion in <b>MPSNeuralNetworkTypes.h</b>. All images in a batch must
    have <b>MPSImage.numberOfImages</b> = 1.</p>
<p class="Pp">Usage:</p>
<p class="Pp"></p>
<pre>
MPSStateBatch * outStates = nil;    // autoreleased
MPSImageBatch * result = [k encodeBatchToCommandBuffer: cmdBuf
                                          sourceImages: sourceImages
                                     destinationStates: &amp;outStates ];
</pre>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The command buffer
<br/>
<i>sourceImages</i> <b>A</b> MPSImages to use as the source images for the
  filter.
<br/>
<i>outStates</i> <b>A</b> pointer to storage to hold a MPSStateBatch* where
  output states are returned</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">An array of MPSImages or MPSTemporaryImages allocated per
  the destinationImageAllocator containing the output of the graph. The offset
  property will be adjusted to reflect the offset used during the encode. The
  returned images will be automatically released when the command buffer
  completes. If you want to keep them around for longer, retain the
  images.</div>
<p class="Pp">Reimplemented in <b>MPSCNNBatchNormalization</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSImage_fP_*___nonnull)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage"><a class="permalink" href="#_-_(_fBMPSImage_fP_*___nonnull)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage">-
  (<b>MPSImage</b> * __nonnull) encodeToCommandBuffer: (nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSImage</b> *__nonnull)
  sourceImage</a></h2>
Encode a <b>MPSCNNKernel</b> into a command Buffer. Create a texture to hold the
  result and return it. In the first iteration on this method,
  encodeToCommandBuffer:sourceImage:destinationImage: some work was left for the
  developer to do in the form of correctly setting the offset property and
  sizing the result buffer. With the introduction of the padding policy (see
  padding property) the filter can do this work itself. If you would like to
  have some input into what sort of <b>MPSImage</b> (e.g. temporary vs. regular)
  or what size it is or where it is allocated, you may set the
  destinationImageAllocator to allocate the image yourself.
<p class="Pp">This method uses the <b>MPSNNPadding</b> padding property to
    figure out how to size the result image and to set the offset property. See
    discussion in <b>MPSNeuralNetworkTypes.h</b>. All images in a batch must
    have <b>MPSImage.numberOfImages</b> = 1.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The command buffer
<br/>
<i>sourceImage</i> <b>A</b> <b>MPSImage</b> to use as the source images for the
  filter.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> <b>MPSImage</b> or <b>MPSTemporaryImage</b>
  allocated per the destinationImageAllocator containing the output of the
  graph. The offset property will be adjusted to reflect the offset used during
  the encode. The returned image will be automatically released when the command
  buffer completes. If you want to keep it around for longer, retain the image.
  (ARC will do this for you if you use it later.)</div>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage(_fBMPSImage_fP_*__nonnull)_destinationImage"><a class="permalink" href="#_-_(void)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage(_fBMPSImage_fP_*__nonnull)_destinationImage">-
  (void) encodeToCommandBuffer: (nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSImage</b> *__nonnull) sourceImage(<b>MPSImage</b>
  *__nonnull) destinationImage</a></h2>
Encode a <b>MPSCNNKernel</b> into a command Buffer. The operation shall proceed
  out-of-place. This is the older style of encode which reads the offset,
  doesn't change it, and ignores the padding method.
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded filter
<br/>
<i>sourceImage</i> <b>A</b> valid <b>MPSImage</b> object containing the source
  image.
<br/>
<i>destinationImage</i> <b>A</b> valid <b>MPSImage</b> to be overwritten by
  result image. destinationImage may not alias sourceImage.</div>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(void)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage(_fBMPSState_fP_*__nonnull)_destinationState(_fBMPSImage_fP_*__nonnull)_destinationImage"><a class="permalink" href="#_-_(void)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage(_fBMPSState_fP_*__nonnull)_destinationState(_fBMPSImage_fP_*__nonnull)_destinationImage">-
  (void) encodeToCommandBuffer: (nonnull id&lt; MTLCommandBuffer &gt;)
  commandBuffer(<b>MPSImage</b> *__nonnull) sourceImage(<b>MPSState</b>
  *__nonnull) destinationState(<b>MPSImage</b> *__nonnull)
  destinationImage</a></h2>
Encode a <b>MPSCNNKernel</b> with a destination state into a command Buffer.
  This is typically used during training. The state is commonly a
  <b>MPSNNGradientState</b>. Please see
  -resultStateForSourceImages:SourceStates: and batch+temporary variants.
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded filter
<br/>
<i>sourceImage</i> <b>A</b> valid <b>MPSImage</b> object containing the source
  image.
<br/>
<i>destinationState</i> <b>A</b> state to be overwritten by additional state
  information.
<br/>
<i>destinationImage</i> <b>A</b> valid <b>MPSImage</b> to be overwritten by
  result image. destinationImage may not alias sourceImage.</div>
<p class="Pp">Reimplemented in <b>MPSCNNBatchNormalization</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSImage_fP_*___nonnull)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage(__autoreleasing__fBMPSState_fP_*__nullable_*__nonnull)_outState(BOOL)_isTemporary"><a class="permalink" href="#_-_(_fBMPSImage_fP_*___nonnull)_encodeToCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage(__autoreleasing__fBMPSState_fP_*__nullable_*__nonnull)_outState(BOOL)_isTemporary">-
  (<b>MPSImage</b> * __nonnull) encodeToCommandBuffer: (nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSImage</b> *__nonnull)
  sourceImage(__autoreleasing <b>MPSState</b> *__nullable *__nonnull)
  outState(BOOL) isTemporary</a></h2>
Encode a <b>MPSCNNKernel</b> into a command Buffer. Create a texture and state
  to hold the results and return them. In the first iteration on this method,
  encodeToCommandBuffer:sourceImage:destinationState:destinationImage: some work
  was left for the developer to do in the form of correctly setting the offset
  property and sizing the result buffer. With the introduction of the padding
  policy (see padding property) the filter can do this work itself. If you would
  like to have some input into what sort of <b>MPSImage</b> (e.g. temporary vs.
  regular) or what size it is or where it is allocated, you may set the
  destinationImageAllocator to allocate the image yourself.
<p class="Pp">This method uses the <b>MPSNNPadding</b> padding property to
    figure out how to size the result image and to set the offset property. See
    discussion in <b>MPSNeuralNetworkTypes.h</b>. All images in a batch must
    have <b>MPSImage.numberOfImages</b> = 1.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The command buffer
<br/>
<i>sourceImage</i> <b>A</b> <b>MPSImage</b> to use as the source images for the
  filter.
<br/>
<i>outState</i> <b>A</b> new state object is returned here.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> <b>MPSImage</b> or <b>MPSTemporaryImage</b>
  allocated per the destinationImageAllocator containing the output of the
  graph. The offset property will be adjusted to reflect the offset used during
  the encode. The returned image will be automatically released when the command
  buffer completes. If you want to keep it around for longer, retain the image.
  (ARC will do this for you if you use it later.)</div>
<p class="Pp">Reimplemented in <b>MPSCNNBatchNormalization</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(nullable_instancetype)__fBinitWithCoder:_fP_(NSCoder_*__nonnull)_aDecoder(nonnull_id__MTLDevice__)_device"><a class="permalink" href="#_-_(nullable_instancetype)__fBinitWithCoder:_fP_(NSCoder_*__nonnull)_aDecoder(nonnull_id__MTLDevice__)_device">-
  (nullable instancetype) <b>initWithCoder:</b> (NSCoder *__nonnull)
  aDecoder(nonnull id&lt; MTLDevice &gt;) device</a></h2>
<b>NSSecureCoding</b> compatability While the standard NSSecureCoding/NSCoding
  method -initWithCoder: should work, since the file can't know which device
  your data is allocated on, we have to guess and may guess incorrectly. To
  avoid that problem, use initWithCoder:device instead.
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>aDecoder</i> The NSCoder subclass with your serialized
  <b>MPSKernel</b>
<br/>
<i>device</i> The MTLDevice on which to make the <b>MPSKernel</b></div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> new <b>MPSKernel</b> object, or nil if
  failure.</div>
<p class="Pp">Reimplemented from <b>MPSKernel</b>.</p>
<p class="Pp">Reimplemented in <b>MPSCNNBinaryConvolution</b>,
    <b>MPSCNNBinaryFullyConnected</b>, <b>MPSCNNConvolutionTranspose</b>,
    <b>MPSCNNFullyConnected</b>, <b>MPSCNNConvolution</b>,
    <b>MPSCNNYOLOLoss</b>, <b>MPSRNNImageInferenceLayer</b>, <b>MPSCNNLoss</b>,
    <b>MPSCNNCrossChannelNormalization</b>, <b>MPSCNNDilatedPoolingMax</b>,
    <b>MPSCNNBatchNormalization</b>, <b>MPSCNNBatchNormalizationStatistics</b>,
    <b>MPSCNNPoolingAverage</b>, <b>MPSCNNPoolingL2Norm</b>,
    <b>MPSCNNLocalContrastNormalization</b>, <b>MPSCNNInstanceNormalization</b>,
    <b>MPSCNNNeuron</b>, <b>MPSNNCropAndResizeBilinear</b>,
    <b>MPSCNNDropout</b>, <b>MPSCNNSpatialNormalization</b>,
    <b>MPSNNResizeBilinear</b>, <b>MPSCNNPooling</b>, and
    <b>MPSCNNPoolingMax</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(nonnull_instancetype)_initWithDevice:_(nonnull_id__MTLDevice__)_device"><a class="permalink" href="#_-_(nonnull_instancetype)_initWithDevice:_(nonnull_id__MTLDevice__)_device">-
  (nonnull instancetype) initWithDevice: (nonnull id&lt; MTLDevice &gt;)
  device</a></h2>
Standard init with default properties per filter type
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device that the filter will be used on.
  May not be NULL.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> pointer to the newly initialized object. This
  will fail, returning nil if the device is not supported. Devices must be
  MTLFeatureSet_iOS_GPUFamily2_v1 or later.</div>
<p class="Pp">Reimplemented from <b>MPSKernel</b>.</p>
<p class="Pp">Reimplemented in <b>MPSCNNBinaryConvolution</b>,
    <b>MPSCNNBinaryFullyConnected</b>, <b>MPSCNNConvolutionTranspose</b>,
    <b>MPSCNNFullyConnected</b>, <b>MPSCNNConvolution</b>,
    <b>MPSCNNYOLOLoss</b>, <b>MPSRNNImageInferenceLayer</b>, <b>MPSCNNLoss</b>,
    <b>MPSCNNCrossChannelNormalization</b>, <b>MPSNNReshape</b>,
    <b>MPSCNNBatchNormalization</b>, <b>MPSCNNBatchNormalizationStatistics</b>,
    <b>MPSNNReduceFeatureChannelsSum</b>, <b>MPSCNNNeuronLinear</b>,
    <b>MPSCNNNeuronReLU</b>, <b>MPSCNNNeuronPReLU</b>,
    <b>MPSCNNNeuronSigmoid</b>, <b>MPSCNNNeuronHardSigmoid</b>,
    <b>MPSCNNNeuronTanH</b>, <b>MPSCNNNeuronAbsolute</b>,
    <b>MPSCNNNeuronSoftPlus</b>, <b>MPSCNNNeuronSoftSign</b>,
    <b>MPSCNNNeuronELU</b>, <b>MPSCNNNeuronReLUN</b>, <b>MPSCNNNeuronPower</b>,
    <b>MPSCNNNeuronExponential</b>, <b>MPSCNNNeuronLogarithm</b>,
    <b>MPSCNNLocalContrastNormalization</b>, <b>MPSCNNInstanceNormalization</b>,
    <b>MPSCNNNeuron</b>, <b>MPSNNCropAndResizeBilinear</b>, <b>MPSNNSlice</b>,
    <b>MPSCNNDropout</b>, <b>MPSCNNUpsampling</b>,
    <b>MPSCNNSpatialNormalization</b>, <b>MPSNNReduceUnary</b>,
    <b>MPSNNReduceRowMin</b>, <b>MPSNNReduceColumnMin</b>,
    <b>MPSNNReduceFeatureChannelsMin</b>,
    <b>MPSNNReduceFeatureChannelsArgumentMin</b>, <b>MPSNNReduceRowMax</b>,
    <b>MPSNNReduceColumnMax</b>, <b>MPSNNReduceFeatureChannelsMax</b>,
    <b>MPSNNReduceFeatureChannelsArgumentMax</b>, <b>MPSNNReduceRowMean</b>,
    <b>MPSNNReduceColumnMean</b>, <b>MPSNNReduceFeatureChannelsMean</b>,
    <b>MPSNNReduceRowSum</b>, <b>MPSNNReduceColumnSum</b>,
    <b>MPSNNResizeBilinear</b>, and <b>MPSCNNPooling</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(BOOL)_isResultStateReusedAcrossBatch"><a class="permalink" href="#_-_(BOOL)_isResultStateReusedAcrossBatch">-
  (BOOL) isResultStateReusedAcrossBatch </a></h2>
Returns YES if the same state is used for every operation in a batch If NO, then
  each image in a MPSImageBatch will need a corresponding (and different) state
  to go with it. Set to YES to avoid allocating redundant state in the case when
  the same state is used all the time. Default: NO
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSStateBatch_fP_*___nullable)_resultStateBatchForSourceImage:_(_fBMPSImageBatch_fP_*__nonnull)_sourceImage(NSArray___fBMPSStateBatch_fP_*___*__nullable)_sourceStates(_fBMPSImageBatch_fP_*__nonnull)_destinationImage"><a class="permalink" href="#_-_(_fBMPSStateBatch_fP_*___nullable)_resultStateBatchForSourceImage:_(_fBMPSImageBatch_fP_*__nonnull)_sourceImage(NSArray___fBMPSStateBatch_fP_*___*__nullable)_sourceStates(_fBMPSImageBatch_fP_*__nonnull)_destinationImage">-
  (<b>MPSStateBatch</b> * __nullable) resultStateBatchForSourceImage:
  (<b>MPSImageBatch</b> *__nonnull) sourceImage(NSArray&lt; <b>MPSStateBatch</b>
  * &gt; *__nullable) sourceStates(<b>MPSImageBatch</b> *__nonnull)
  destinationImage</a></h2>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSState_fP_*___nullable)_resultStateForSourceImage:_(_fBMPSImage_fP_*__nonnull)_sourceImage(NSArray___fBMPSState_fP_*___*__nullable)_sourceStates(_fBMPSImage_fP_*__nonnull)_destinationImage"><a class="permalink" href="#_-_(_fBMPSState_fP_*___nullable)_resultStateForSourceImage:_(_fBMPSImage_fP_*__nonnull)_sourceImage(NSArray___fBMPSState_fP_*___*__nullable)_sourceStates(_fBMPSImage_fP_*__nonnull)_destinationImage">-
  (<b>MPSState</b> * __nullable) resultStateForSourceImage: (<b>MPSImage</b>
  *__nonnull) sourceImage(NSArray&lt; <b>MPSState</b> * &gt; *__nullable)
  sourceStates(<b>MPSImage</b> *__nonnull) destinationImage</a></h2>
Allocate a <b>MPSState</b> (subclass) to hold the results from a
  -encodeBatchToCommandBuffer... operation <b>A</b> graph may need to allocate
  storage up front before executing. This may be necessary to avoid using too
  much memory and to manage large batches. The function should allocate any
  <b>MPSState</b> objects that will be produced by an -encode call with the
  indicated sourceImages and sourceStates inputs. Though the states can be
  further adjusted in the ensuing -encode call, the states should be initialized
  with all important data and all MTLResource storage allocated. The data stored
  in the MTLResource need not be initialized, unless the ensuing -encode call
  expects it to be.
<p class="Pp">The MTLDevice used by the result is derived from the source image.
    The padding policy will be applied to the filter before this is called to
    give it the chance to configure any properties like
    <b>MPSCNNKernel.offset</b>.</p>
<p class="Pp">CAUTION: The kernel must have all properties set to values that
    will ultimately be passed to the -encode call that writes to the state,
    before -resultStateForSourceImages:sourceStates:destinationImage: is called
    or behavior is undefined. Please note that
    -destinationImageDescriptorForSourceImages:sourceStates: will alter some of
    these properties automatically based on the padding policy. If you intend to
    call that to make the destination image, then you should call that before
    -resultStateForSourceImages:sourceStates:destinationImage:. This will ensure
    the properties used in the encode call and in the destination image creation
    match those used to configure the state.</p>
<p class="Pp">The following order is recommended:</p>
<p class="Pp"></p>
<pre>
// Configure MPSCNNKernel properties first
kernel.edgeMode = MPSImageEdgeModeZero;
kernel.destinationFeatureChannelOffset = 128; // concatenation without the copy
// ALERT: will change MPSCNNKernel properties
MPSImageDescriptor * d = [kernel destinationImageDescriptorForSourceImage: source
                                                             sourceStates: states];
MPSTemporaryImage * dest = [MPSTemporaryImage temporaryImageWithCommandBuffer: cmdBuf
                                                              imageDescriptor: d];
// Now that all properties are configured properly, we can make the result state
// and call encode.
MPSState * __nullable destState = [kernel resultStateForSourceImage: source
                                                       sourceStates: states
                                                   destinationImage: dest];
// This form of -encode will be declared by the MPSCNNKernel subclass
[kernel encodeToCommandBuffer: cmdBuf
                  sourceImage: source
             destinationState: destState
             destinationImage: dest ];
</pre>
<p class="Pp">Default: returns nil</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>sourceImage</i> The <b>MPSImage</b> consumed by the
  associated -encode call.
<br/>
<i>sourceStates</i> The list of MPSStates consumed by the associated -encode
  call, for a batch size of 1.
<br/>
<i>destinationImage</i> The destination image for the encode call</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">The list of states produced by the -encode call for batch
  size of 1. When the batch size is not 1, this function will be called
  repeatedly unless -isResultStateReusedAcrossBatch returns YES. If
  -isResultStateReusedAcrossBatch returns YES, then it will be called once per
  batch and the MPSStateBatch array will contain MPSStateBatch.length references
  to the same object.</div>
<p class="Pp">Reimplemented in <b>MPSCNNConvolution</b>,
    <b>MPSCNNBatchNormalization</b>, and <b>MPSCNNInstanceNormalization</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSStateBatch_fP_*___nullable)_temporaryResultStateBatchForCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImage(NSArray___fBMPSStateBatch_fP_*___*__nullable)_sourceStates(_fBMPSImageBatch_fP_*__nonnull)_destinationImage"><a class="permalink" href="#_-_(_fBMPSStateBatch_fP_*___nullable)_temporaryResultStateBatchForCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImageBatch_fP_*__nonnull)_sourceImage(NSArray___fBMPSStateBatch_fP_*___*__nullable)_sourceStates(_fBMPSImageBatch_fP_*__nonnull)_destinationImage">-
  (<b>MPSStateBatch</b> * __nullable) temporaryResultStateBatchForCommandBuffer:
  (nonnull id&lt; MTLCommandBuffer &gt;) commandBuffer(<b>MPSImageBatch</b>
  *__nonnull) sourceImage(NSArray&lt; <b>MPSStateBatch</b> * &gt; *__nullable)
  sourceStates(<b>MPSImageBatch</b> *__nonnull) destinationImage</a></h2>
Reimplemented in <b>MPSCNNConvolution</b>.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(_fBMPSState_fP_*___nullable)_temporaryResultStateForCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage(NSArray___fBMPSState_fP_*___*__nullable)_sourceStates(_fBMPSImage_fP_*__nonnull)_destinationImage"><a class="permalink" href="#_-_(_fBMPSState_fP_*___nullable)_temporaryResultStateForCommandBuffer:_(nonnull_id__MTLCommandBuffer__)_commandBuffer(_fBMPSImage_fP_*__nonnull)_sourceImage(NSArray___fBMPSState_fP_*___*__nullable)_sourceStates(_fBMPSImage_fP_*__nonnull)_destinationImage">-
  (<b>MPSState</b> * __nullable) temporaryResultStateForCommandBuffer: (nonnull
  id&lt; MTLCommandBuffer &gt;) commandBuffer(<b>MPSImage</b> *__nonnull)
  sourceImage(NSArray&lt; <b>MPSState</b> * &gt; *__nullable)
  sourceStates(<b>MPSImage</b> *__nonnull) destinationImage</a></h2>
Allocate a temporary <b>MPSState</b> (subclass) to hold the results from a
  -encodeBatchToCommandBuffer... operation <b>A</b> graph may need to allocate
  storage up front before executing. This may be necessary to avoid using too
  much memory and to manage large batches. The function should allocate any
  <b>MPSState</b> objects that will be produced by an -encode call with the
  indicated sourceImages and sourceStates inputs. Though the states can be
  further adjusted in the ensuing -encode call, the states should be initialized
  with all important data and all MTLResource storage allocated. The data stored
  in the MTLResource need not be initialized, unless the ensuing -encode call
  expects it to be.
<p class="Pp">The MTLDevice used by the result is derived from the command
    buffer. The padding policy will be applied to the filter before this is
    called to give it the chance to configure any properties like
    <b>MPSCNNKernel.offset</b>.</p>
<p class="Pp">CAUTION: The kernel must have all properties set to values that
    will ultimately be passed to the -encode call that writes to the state,
    before -resultStateForSourceImages:sourceStates:destinationImage: is called
    or behavior is undefined. Please note that
    -destinationImageDescriptorForSourceImages:sourceStates:destinationImage:
    will alter some of these properties automatically based on the padding
    policy. If you intend to call that to make the destination image, then you
    should call that before
    -resultStateForSourceImages:sourceStates:destinationImage:. This will ensure
    the properties used in the encode call and in the destination image creation
    match those used to configure the state.</p>
<p class="Pp">The following order is recommended:</p>
<p class="Pp"></p>
<pre>
// Configure MPSCNNKernel properties first
kernel.edgeMode = MPSImageEdgeModeZero;
kernel.destinationFeatureChannelOffset = 128; // concatenation without the copy
// ALERT: will change MPSCNNKernel properties
MPSImageDescriptor * d = [kernel destinationImageDescriptorForSourceImage: source
                                                             sourceStates: states];
MPSTemporaryImage * dest = [MPSTemporaryImage temporaryImageWithCommandBuffer: cmdBuf
                                                              imageDescriptor: d];
// Now that all properties are configured properly, we can make the result state
// and call encode.
MPSState * __nullable destState = [kernel temporaryResultStateForCommandBuffer: cmdBuf
                                                                   sourceImage: source
                                                                  sourceStates: states];
// This form of -encode will be declared by the MPSCNNKernel subclass
[kernel encodeToCommandBuffer: cmdBuf
                  sourceImage: source
             destinationState: destState
             destinationImage: dest ];
</pre>
<p class="Pp">Default: returns nil</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> The command buffer to allocate the
  temporary storage against The state will only be valid on this command buffer.
<br/>
<i>sourceImage</i> The <b>MPSImage</b> consumed by the associated -encode call.
<br/>
<i>sourceStates</i> The list of MPSStates consumed by the associated -encode
  call, for a batch size of 1.
<br/>
<i>destinationImage</i> The destination image for the encode call</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">The list of states produced by the -encode call for batch
  size of 1. When the batch size is not 1, this function will be called
  repeatedly unless -isResultStateReusedAcrossBatch returns YES. If
  -isResultStateReusedAcrossBatch returns YES, then it will be called once per
  batch and the MPSStateBatch array will contain MPSStateBatch.length references
  to the same object.</div>
<p class="Pp">Reimplemented in <b>MPSCNNConvolution</b>,
    <b>MPSCNNBatchNormalization</b>, and <b>MPSCNNInstanceNormalization</b>.</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss" id="_-_clipRect_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_clipRect_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  clipRect [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
An optional clip rectangle to use when writing data. Only the pixels in the
  rectangle will be overwritten. <b>A</b> MTLRegion that indicates which part of
  the destination to overwrite. If the clipRect does not lie completely within
  the destination image, the intersection between clip rectangle and destination
  bounds is used. Default: MPSRectNoClip (<b>MPSKernel::MPSRectNoClip</b>)
  indicating the entire image. clipRect.origin.z is the index of starting
  destination image in batch processing mode. clipRect.size.depth is the number
  of images to process in batch processing mode.
<p class="Pp">See Also: <b>MetalPerformanceShaders.h</b>
  subsubsection_clipRect</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_destinationFeatureChannelOffset_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_destinationFeatureChannelOffset_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  destinationFeatureChannelOffset [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></a></h2>
The number of channels in the destination <b>MPSImage</b> to skip before writing
  output. This is the starting offset into the destination image in the feature
  channel dimension at which destination data is written. This allows an
  application to pass a subset of all the channels in <b>MPSImage</b> as output
  of <b>MPSKernel</b>. E.g. Suppose <b>MPSImage</b> has 24 channels and a
  <b>MPSKernel</b> outputs 8 channels. If we want channels 8 to 15 of this
  <b>MPSImage</b> to be used as output, we can set
  destinationFeatureChannelOffset = 8. Note that this offset applies
  independently to each image when the <b>MPSImage</b> is a container for
  multiple images and the <b>MPSCNNKernel</b> is processing multiple images
  (clipRect.size.depth &gt; 1). The default value is 0 and any value specifed
  shall be a multiple of 4. If <b>MPSKernel</b> outputs N channels, the
  destination image MUST have at least destinationFeatureChannelOffset + N
  channels. Using a destination image with insufficient number of feature
  channels will result in an error. E.g. if the <b>MPSCNNConvolution</b> outputs
  32 channels, and the destination has 64 channels, then it is an error to set
  destinationFeatureChannelOffset &gt; 32.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(id__fBMPSNNPadding_fP__id_MPSImageAllocator_)_destinationImageAllocator_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__retain__fP"><a class="permalink" href="#_-_(id__fBMPSNNPadding_fP__id_MPSImageAllocator_)_destinationImageAllocator_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__retain__fP">-
  (id&lt;<b>MPSNNPadding</b>&gt; id&lt;MPSImageAllocator&gt;)
  destinationImageAllocator [read]<b>, [write]</b>, [nonatomic]<b>,
  [retain]</b></a></h2>
Method to allocate the result image for -encodeToCommandBuffer:sourceImage:
  Default: <b>defaultAllocator (MPSTemporaryImage)</b>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_dilationRateX_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_dilationRateX_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  dilationRateX [read]<b>, [nonatomic]</b>, [assign]<b></b></a></h2>
Stride in source coordinates from one kernel tap to the next in the X dimension.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(NSUInteger)_dilationRateY_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_(NSUInteger)_dilationRateY_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  (NSUInteger) dilationRateY [read]<b>, [nonatomic]</b>,
  [assign]<b></b></a></h2>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_edgeMode_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_edgeMode_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  edgeMode [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
The MPSImageEdgeMode to use when texture reads stray off the edge of an image
  Most <b>MPSKernel</b> objects can read off the edge of the source image. This
  can happen because of a negative offset property, because the offset +
  clipRect.size is larger than the source image or because the filter looks at
  neighboring pixels, such as a Convolution filter. Default:
  MPSImageEdgeModeZero.
<p class="Pp">See Also: <b>MetalPerformanceShaders.h</b> subsubsection_edgemode
    Note: For <b>MPSCNNPoolingAverage</b> specifying edge mode
    <b>MPSImageEdgeModeClamp</b> is interpreted as a 'shrink-to-edge' operation,
    which shrinks the effective filtering window to remain within the source
    image borders.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_isBackwards_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_isBackwards_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  isBackwards [read]<b>, [nonatomic]</b>, [assign]<b></b></a></h2>
YES if the filter operates backwards. This influences how strideInPixelsX/Y
  should be interpreted. Most filters either have stride 1 or are reducing,
  meaning that the result image is smaller than the original by roughly a factor
  of the stride. <b>A</b> few 'backward' filters (e.g convolution transpose) are
  intended to 'undo' the effects of an earlier forward filter, and so enlarge
  the image. The stride is in the destination coordinate frame rather than the
  source coordinate frame.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_(BOOL_BOOL)_isStateModified_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_(BOOL_BOOL)_isStateModified_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  (BOOL BOOL) isStateModified [read]<b>, [nonatomic]</b>,
  [assign]<b></b></a></h2>
Returns true if the -encode call modifies the state object it accepts.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_kernelHeight_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_kernelHeight_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  kernelHeight [read]<b>, [nonatomic]</b>, [assign]<b></b></a></h2>
The height of the <b>MPSCNNKernel</b> filter window This is the vertical
  diameter of the region read by the filter for each result pixel. If the
  <b>MPSCNNKernel</b> does not have a filter window, then 1 will be returned.
<p class="Pp">Warning: This property was lowered to this class in ios/tvos 11
    The property may not be available on iOS/tvOS 10 for all subclasses of
    <b>MPSCNNKernel</b></p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_kernelWidth_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_kernelWidth_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  kernelWidth [read]<b>, [nonatomic]</b>, [assign]<b></b></a></h2>
The width of the <b>MPSCNNKernel</b> filter window This is the horizontal
  diameter of the region read by the filter for each result pixel. If the
  <b>MPSCNNKernel</b> does not have a filter window, then 1 will be returned.
<p class="Pp">Warning: This property was lowered to this class in ios/tvos 11
    The property may not be available on iOS/tvOS 10 for all subclasses of
    <b>MPSCNNKernel</b></p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_offset_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_offset_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  offset [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
The position of the destination clip rectangle origin relative to the source
  buffer. The offset is defined to be the position of clipRect.origin in source
  coordinates. Default: {0,0,0}, indicating that the top left corners of the
  clipRect and source image align. offset.z is the index of starting source
  image in batch processing mode.
<p class="Pp">See Also: <b>MetalPerformanceShaders.h</b>
  subsubsection_mpsoffset</p>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_padding_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_padding_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  padding [read]<b>, [write]</b>, [nonatomic]<b>, [assign]</b></a></h2>
The padding method used by the filter This influences how the destination image
  is sized and how the offset into the source image is set. It is used by the
  -encode methods that return a <b>MPSImage</b> from the left hand side.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_sourceFeatureChannelMaxCount_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_sourceFeatureChannelMaxCount_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  sourceFeatureChannelMaxCount [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></a></h2>
The maximum number of channels in the source <b>MPSImage</b> to use Most filters
  can insert a slice operation into the filter for free. Use this to limit the
  size of the feature channel slice taken from the input image. If the value is
  too large, it is truncated to be the remaining size in the image after the
  sourceFeatureChannelOffset is taken into account. Default: ULONG_MAX
</section>
<section class="Ss">
<h2 class="Ss" id="_-_sourceFeatureChannelOffset_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_sourceFeatureChannelOffset_fC__read__fP,__fC__write__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  sourceFeatureChannelOffset [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></a></h2>
The number of channels in the source <b>MPSImage</b> to skip before reading the
  input. This is the starting offset into the source image in the feature
  channel dimension at which source data is read. Unit: feature channels This
  allows an application to read a subset of all the channels in <b>MPSImage</b>
  as input of <b>MPSKernel</b>. E.g. Suppose <b>MPSImage</b> has 24 channels and
  a <b>MPSKernel</b> needs to read 8 channels. If we want channels 8 to 15 of
  this <b>MPSImage</b> to be used as input, we can set
  sourceFeatureChannelOffset = 8. Note that this offset applies independently to
  each image when the <b>MPSImage</b> is a container for multiple images and the
  <b>MPSCNNKernel</b> is processing multiple images (clipRect.size.depth &gt;
  1). The default value is 0 and any value specifed shall be a multiple of 4. If
  <b>MPSKernel</b> inputs N channels, the source image MUST have at least
  sourceFeatureChannelOffset + N channels. Using a source image with
  insufficient number of feature channels will result in an error. E.g. if the
  <b>MPSCNNConvolution</b> inputs 32 channels, and the source has 64 channels,
  then it is an error to set sourceFeatureChannelOffset &gt; 32.
</section>
<section class="Ss">
<h2 class="Ss" id="_-_strideInPixelsX_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_strideInPixelsX_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  strideInPixelsX [read]<b>, [nonatomic]</b>, [assign]<b></b></a></h2>
The downsampling (or upsampling if a backwards filter) factor in the horizontal
  dimension If the filter does not do up or downsampling, 1 is returned.
<p class="Pp"></p>
<pre>
        Warning: This property was lowered to this class in ios/tvos 11
                 The property may not be available on iOS/tvOS 10 for
                 all subclasses of MPSCNNKernel
</pre>
</section>
<section class="Ss">
<h2 class="Ss" id="_-_strideInPixelsY_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP"><a class="permalink" href="#_-_strideInPixelsY_fC__read__fP,__fC__nonatomic__fP,__fC__assign__fP">-
  strideInPixelsY [read]<b>, [nonatomic]</b>, [assign]<b></b></a></h2>
The downsampling (or upsampling if a backwards filter) factor in the vertical
  dimension If the filter does not do up or downsampling, 1 is returned.
<p class="Pp"></p>
<pre>
        Warning: This property was lowered to this class in ios/tvos 11
                 The property may not be available on iOS/tvOS 10 for
                 all subclasses of MPSCNNKernel
</pre>
<p class="Pp"></p>
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
Generated automatically by Doxygen for MetalPerformanceShaders.framework from
  the source code.
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
