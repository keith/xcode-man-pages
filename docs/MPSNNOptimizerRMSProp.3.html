<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>

<style>
@media (prefers-color-scheme: dark) {
  body {
    background: #000;
    color: #d0d0d0;
  }

  a, a:visited {
    color: #1899eb;
  }
}
</style>

  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    .Nd, .Bf, .Op { display: inline; }
    .Pa, .Ad { font-style: italic; }
    .Ms { font-weight: bold; }
    .Bl-diag > dt { font-weight: bold; }
    code.Nm, .Fl, .Cm, .Ic, code.In, .Fd, .Fn, .Cd { font-weight: bold;
      font-family: inherit; }
  </style>
  <title>MPSNNOptimizerRMSProp(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSNNOptimizerRMSProp(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSNNOptimizerRMSProp(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
<p class="Pp">MPSNNOptimizerRMSProp</p>
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSNNOptimizers.h&gt;</p>
<p class="Pp">Inherits <b>MPSNNOptimizer</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
<p class="Pp">(nonnull instancetype) - <b>initWithDevice:</b>
  <br/>
  (nonnull instancetype) - <b>initWithDevice:learningRate:</b>
  <br/>
  (nonnull instancetype) -
    <b>initWithDevice:decay:epsilon:optimizerDescriptor:</b>
  <br/>
  (void) -
    <b>encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputSumOfSquaresVector:resultValuesVector:</b>
  <br/>
  (void) -
    <b>encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputSumOfSquaresVectors:resultState:</b>
  <br/>
  (void) -
    <b>encodeToCommandBuffer:batchNormalizationState:inputSumOfSquaresVectors:resultState:</b>
  <br/>
  (void) -
    <b>encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputSumOfSquaresVectors:resultState:</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
<p class="Pp">double <b>decay</b>
  <br/>
  float <b>epsilon</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Additional_Inherited_Members"><a class="permalink" href="#Additional_Inherited_Members">Additional
  Inherited Members</a></h2>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
<p class="Pp">The <b>MPSNNOptimizerRMSProp</b> performs an RMSProp Update
    RMSProp is also known as root mean square propagation.</p>
<p class="Pp">s[t] = decay * s[t-1] + (1 - decay) * (g ^ 2) variable = variable
    - learningRate * g / (sqrt(s[t]) + epsilon)</p>
<p class="Pp">where, g is gradient of error wrt variable s[t] is weighted sum of
    squares of gradients</p>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- (void) encodeToCommandBuffer: (__nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSCNNBatchNormalizationState</b>
  *__nonnull)
  batchNormalizationGradientState(<b>MPSCNNBatchNormalizationState</b>
  *__nonnull) batchNormalizationSourceState(nullable NSArray&lt;
  <b>MPSVector</b> * &gt; *) inputSumOfSquaresVectors(nonnull
  <b>MPSCNNNormalizationGammaAndBetaState</b> *) resultState</h2>
<p class="Pp">Encode an <b>MPSNNOptimizerRMSProp</b> object to a command buffer
    to perform out of place update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>batchNormalizationGradientState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with gradients for this update.
<br/>
<i>batchNormalizationSourceState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with original gamma/beta for this update.
<br/>
<i>inputSumOfSquaresVectors</i> An array <b>MPSVector</b> object which specifies
  the gradient sumOfSquares vectors which will be updated and overwritten. The
  index 0 corresponds to gamma, index 1 corresponds to beta, array can be of
  size 1 in which case beta won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNNormalizationGammaAndBetaState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
<br/>
        s[t]     = decay * s[t-1] + (1 - decay) * (g ^ 2)
<br/>
        variable = variable - learningRate * g / (sqrt(s[t]) + epsilon)
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          s[t] is weighted sum of squares of gradients.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeToCommandBuffer: (__nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSCNNBatchNormalizationState</b>
  *__nonnull) batchNormalizationState(nullable NSArray&lt; <b>MPSVector</b> *
  &gt; *) inputSumOfSquaresVectors(nonnull
  <b>MPSCNNNormalizationGammaAndBetaState</b> *) resultState</h2>
<p class="Pp">Encode an <b>MPSNNOptimizerRMSProp</b> object to a command buffer
    to perform out of place update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>batchNormalizationState</i> <b>A</b> valid
  <b>MPSCNNBatchNormalizationState</b> object which specifies the input state
  with gradients and original gamma/beta for this update.
<br/>
<i>inputSumOfSquaresVectors</i> An array <b>MPSVector</b> object which specifies
  the gradient sumOfSquares vectors which will be updated and overwritten. The
  index 0 corresponds to gamma, index 1 corresponds to beta, array can be of
  size 1 in which case beta won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNNormalizationGammaAndBetaState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
<br/>
        s[t]     = decay * s[t-1] + (1 - decay) * (g ^ 2)
<br/>
        variable = variable - learningRate * g / (sqrt(s[t]) + epsilon)
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          s[t] is weighted sum of squares of gradients.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeToCommandBuffer: (__nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(<b>MPSCNNConvolutionGradientState</b>
  *__nonnull)
  convolutionGradientState(<b>MPSCNNConvolutionWeightsAndBiasesState</b>
  *__nonnull) convolutionSourceState(nullable NSArray&lt; <b>MPSVector</b> *
  &gt; *) inputSumOfSquaresVectors(nonnull
  <b>MPSCNNConvolutionWeightsAndBiasesState</b> *) resultState</h2>
<p class="Pp">Encode an <b>MPSNNOptimizerRMSProp</b> object to a command buffer
    to perform out of place update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>convolutionGradientState</i> <b>A</b> valid
  <b>MPSCNNConvolutionGradientState</b> object which specifies the input state
  with gradients for this update.
<br/>
<i>convolutionSourceState</i> <b>A</b> valid
  <b>MPSCNNConvolutionWeightsAndBiasesState</b> object which specifies the input
  state with values to be updated.
<br/>
<i>inputSumOfSquaresVectors</i> An array <b>MPSVector</b> object which specifies
  the gradient sumOfSquares vectors which will be updated and overwritten. The
  index 0 corresponds to weights, index 1 corresponds to biases, array can be of
  size 1 in which case biases won't be updated
<br/>
<i>resultState</i> <b>A</b> valid <b>MPSCNNConvolutionWeightsAndBiasesState</b>
  object which specifies the resultValues state which will be updated and
  overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
<br/>
        s[t]     = decay * s[t-1] + (1 - decay) * (g ^ 2)
<br/>
        variable = variable - learningRate * g / (sqrt(s[t]) + epsilon)
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          s[t] is weighted sum of squares of gradients.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeToCommandBuffer: (nonnull id&lt; MTLCommandBuffer
  &gt;) commandBuffer(nonnull <b>MPSVector</b> *) inputGradientVector(nonnull
  <b>MPSVector</b> *) inputValuesVector(nonnull <b>MPSVector</b> *)
  inputSumOfSquaresVector(nonnull <b>MPSVector</b> *) resultValuesVector</h2>
<p class="Pp">Encode an <b>MPSNNOptimizerRMSProp</b> object to a command buffer
    to perform out of place update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded kernel.
<br/>
<i>inputGradientVector</i> <b>A</b> valid <b>MPSVector</b> object which
  specifies the input vector of gradients for this update.
<br/>
<i>inputValuesVector</i> <b>A</b> valid <b>MPSVector</b> object which specifies
  the input vector of values to be updated.
<br/>
<i>inputSumOfSquaresVector</i> <b>A</b> valid <b>MPSVector</b> object which
  specifies the gradient velocity vector which will be updated and overwritten.
<br/>
<i>resultValuesVector</i> <b>A</b> valid <b>MPSVector</b> object which specifies
  the resultValues vector which will be updated and overwritten.</div>
<p class="Pp">The following operations would be applied</p>
<p class="Pp"></p>
<pre>
<br/>
        s[t]     = decay * s[t-1] + (1 - decay) * (g ^ 2)
<br/>
        variable = variable - learningRate * g / (sqrt(s[t]) + epsilon)
<br/>
        where,
<br/>
          g    is gradient of error wrt variable
<br/>
          s[t] is weighted sum of squares of gradients.fi</pre>
<pre>
<br/>
 </pre>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) initWithDevice: (nonnull id&lt;
  MTLDevice &gt;) device</h2>
<p class="Pp">Standard init with default properties per filter type</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device that the filter will be used on.
  May not be NULL.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">a pointer to the newly initialized object. This will
  fail, returning nil if the device is not supported. Devices must be
  MTLFeatureSet_iOS_GPUFamily2_v1 or later.</div>
<p class="Pp">Reimplemented from <b>MPSNNOptimizer</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt;
  MTLDevice &gt;) device(double) decay(float) epsilon(nonnull
  <b>MPSNNOptimizerDescriptor</b> *) optimizerDescriptor</h2>
<p class="Pp">Full initialization for the rmsProp update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device on which the kernel will
  execute.
<br/>
<i>decay</i> The decay to update sumOfSquares
<br/>
<i>epsilon</i> The epsilon which will be applied
<br/>
<i>optimizerDescriptor</i> The optimizerDescriptor which will have a bunch of
  properties to be applied</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSNNOptimizerRMSProp</b> object or
  nil, if failure.</div>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt;
  MTLDevice &gt;) device(float) learningRate</h2>
<p class="Pp">Convenience initialization for the RMSProp update</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device on which the kernel will
  execute.
<br/>
<i>learningRate</i> The learningRate which will be applied</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSNNOptimizerRMSProp</b> object or
  nil, if failure.</div>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- decay [read]<b>, [nonatomic]</b>, [assign]<b></b></h2>
<p class="Pp">The decay at which we update sumOfSquares Default value is 0.9</p>
</section>
<section class="Ss">
<h2 class="Ss">- epsilon [read]<b>, [nonatomic]</b>, [assign]<b></b></h2>
<p class="Pp">The epsilon at which we update values This value is usually used
    to ensure to avoid divide by 0, default value is 1e-8</p>
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
<p class="Pp">Generated automatically by Doxygen for
    MetalPerformanceShaders.framework from the source code.</p>
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
